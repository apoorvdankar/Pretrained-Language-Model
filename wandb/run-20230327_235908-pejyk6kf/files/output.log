03/27 11:59:09 PM device: cuda n_gpu: 1
03/27 11:59:09 PM Writing example 0 of 8551
03/27 11:59:09 PM *** Example ***
03/27 11:59:09 PM guid: train-0
03/27 11:59:09 PM tokens: [CLS] our friends won ' t buy this analysis , let alone the next one we propose . [SEP]
03/27 11:59:09 PM input_ids: 101 2256 2814 2180 1005 1056 4965 2023 4106 1010 2292 2894 1996 2279 2028 2057 16599 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/27 11:59:09 PM input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/27 11:59:09 PM segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/27 11:59:09 PM label: 1
03/27 11:59:09 PM label_id: 1
03/27 11:59:10 PM Writing example 0 of 1043
03/27 11:59:10 PM *** Example ***
03/27 11:59:10 PM guid: dev-0
03/27 11:59:10 PM tokens: [CLS] the sailors rode the breeze clear of the rocks . [SEP]
03/27 11:59:10 PM input_ids: 101 1996 11279 8469 1996 9478 3154 1997 1996 5749 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/27 11:59:10 PM input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/27 11:59:10 PM segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/27 11:59:10 PM label: 1
03/27 11:59:10 PM label_id: 1
03/27 11:59:10 PM loading archive file /w/331/adeemj/csc2516_proj/models/CoLA/models--textattack--bert-base-uncased-CoLA/snapshots/5fed03dd6bc5f0b40e86cb04cd1a16eb404ba391/
03/27 11:59:10 PM Model config {
  "architectures": [
    "BertForSequenceClassification"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "cola",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pre_trained": "",
  "training": "",
  "type_vocab_size": 2,
  "vocab_size": 30522
}
03/27 11:59:12 PM Loading model /w/331/adeemj/csc2516_proj/models/CoLA/models--textattack--bert-base-uncased-CoLA/snapshots/5fed03dd6bc5f0b40e86cb04cd1a16eb404ba391/pytorch_model.bin
03/27 11:59:13 PM loading model...
03/27 11:59:13 PM done!
03/27 11:59:13 PM Weights of TinyBertForSequenceClassification not initialized from pretrained model: ['fit_dense.weight', 'fit_dense.bias']
03/27 11:59:15 PM loading archive file /w/331/adeemj/csc2516_proj/models/CoLA/KL_ATTN_SWEEP_BATCHMEAN/TempTinyBERT_CoLA_4L_312D_kl_weight0.01
03/27 11:59:15 PM Model config {
  "attention_probs_dropout_prob": 0.1,
  "cell": {},
  "emb_size": 312,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 312,
  "initializer_range": 0.02,
  "intermediate_size": 1200,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 4,
  "pre_trained": "",
  "structure": [],
  "training": "",
  "type_vocab_size": 2,
  "vocab_size": 30522
}
03/27 11:59:15 PM Loading model /w/331/adeemj/csc2516_proj/models/CoLA/KL_ATTN_SWEEP_BATCHMEAN/TempTinyBERT_CoLA_4L_312D_kl_weight0.01/pytorch_model.bin
03/27 11:59:16 PM loading model...
03/27 11:59:16 PM done!
03/27 11:59:16 PM ***** Running training *****
03/27 11:59:16 PM   Num examples = 8551
03/27 11:59:16 PM   Batch size = 16
03/27 11:59:16 PM   Num steps = 1602
03/27 11:59:16 PM n: bert.embeddings.word_embeddings.weight
03/27 11:59:16 PM n: bert.embeddings.position_embeddings.weight
03/27 11:59:16 PM n: bert.embeddings.token_type_embeddings.weight
03/27 11:59:16 PM n: bert.embeddings.LayerNorm.weight
03/27 11:59:16 PM n: bert.embeddings.LayerNorm.bias
03/27 11:59:16 PM n: bert.encoder.layer.0.attention.self.query.weight
03/27 11:59:16 PM n: bert.encoder.layer.0.attention.self.query.bias
03/27 11:59:16 PM n: bert.encoder.layer.0.attention.self.key.weight
03/27 11:59:16 PM n: bert.encoder.layer.0.attention.self.key.bias
03/27 11:59:16 PM n: bert.encoder.layer.0.attention.self.value.weight
03/27 11:59:16 PM n: bert.encoder.layer.0.attention.self.value.bias
03/27 11:59:16 PM n: bert.encoder.layer.0.attention.output.dense.weight
03/27 11:59:16 PM n: bert.encoder.layer.0.attention.output.dense.bias
03/27 11:59:16 PM n: bert.encoder.layer.0.attention.output.LayerNorm.weight
03/27 11:59:16 PM n: bert.encoder.layer.0.attention.output.LayerNorm.bias
03/27 11:59:16 PM n: bert.encoder.layer.0.intermediate.dense.weight
03/27 11:59:16 PM n: bert.encoder.layer.0.intermediate.dense.bias
03/27 11:59:16 PM n: bert.encoder.layer.0.output.dense.weight
03/27 11:59:16 PM n: bert.encoder.layer.0.output.dense.bias
03/27 11:59:16 PM n: bert.encoder.layer.0.output.LayerNorm.weight
03/27 11:59:16 PM n: bert.encoder.layer.0.output.LayerNorm.bias
03/27 11:59:16 PM n: bert.encoder.layer.1.attention.self.query.weight
03/27 11:59:16 PM n: bert.encoder.layer.1.attention.self.query.bias
03/27 11:59:16 PM n: bert.encoder.layer.1.attention.self.key.weight
03/27 11:59:16 PM n: bert.encoder.layer.1.attention.self.key.bias
03/27 11:59:16 PM n: bert.encoder.layer.1.attention.self.value.weight
03/27 11:59:16 PM n: bert.encoder.layer.1.attention.self.value.bias
03/27 11:59:16 PM n: bert.encoder.layer.1.attention.output.dense.weight
03/27 11:59:16 PM n: bert.encoder.layer.1.attention.output.dense.bias
03/27 11:59:16 PM n: bert.encoder.layer.1.attention.output.LayerNorm.weight
03/27 11:59:16 PM n: bert.encoder.layer.1.attention.output.LayerNorm.bias
03/27 11:59:16 PM n: bert.encoder.layer.1.intermediate.dense.weight
03/27 11:59:16 PM n: bert.encoder.layer.1.intermediate.dense.bias
03/27 11:59:16 PM n: bert.encoder.layer.1.output.dense.weight
03/27 11:59:16 PM n: bert.encoder.layer.1.output.dense.bias
03/27 11:59:16 PM n: bert.encoder.layer.1.output.LayerNorm.weight
03/27 11:59:16 PM n: bert.encoder.layer.1.output.LayerNorm.bias
03/27 11:59:16 PM n: bert.encoder.layer.2.attention.self.query.weight
03/27 11:59:16 PM n: bert.encoder.layer.2.attention.self.query.bias
03/27 11:59:16 PM n: bert.encoder.layer.2.attention.self.key.weight
03/27 11:59:16 PM n: bert.encoder.layer.2.attention.self.key.bias
03/27 11:59:16 PM n: bert.encoder.layer.2.attention.self.value.weight
03/27 11:59:16 PM n: bert.encoder.layer.2.attention.self.value.bias
03/27 11:59:16 PM n: bert.encoder.layer.2.attention.output.dense.weight
03/27 11:59:16 PM n: bert.encoder.layer.2.attention.output.dense.bias
03/27 11:59:16 PM n: bert.encoder.layer.2.attention.output.LayerNorm.weight
03/27 11:59:16 PM n: bert.encoder.layer.2.attention.output.LayerNorm.bias
03/27 11:59:16 PM n: bert.encoder.layer.2.intermediate.dense.weight
03/27 11:59:16 PM n: bert.encoder.layer.2.intermediate.dense.bias
03/27 11:59:16 PM n: bert.encoder.layer.2.output.dense.weight
03/27 11:59:16 PM n: bert.encoder.layer.2.output.dense.bias
03/27 11:59:16 PM n: bert.encoder.layer.2.output.LayerNorm.weight
03/27 11:59:16 PM n: bert.encoder.layer.2.output.LayerNorm.bias
03/27 11:59:16 PM n: bert.encoder.layer.3.attention.self.query.weight
03/27 11:59:16 PM n: bert.encoder.layer.3.attention.self.query.bias
03/27 11:59:16 PM n: bert.encoder.layer.3.attention.self.key.weight
03/27 11:59:16 PM n: bert.encoder.layer.3.attention.self.key.bias
03/27 11:59:16 PM n: bert.encoder.layer.3.attention.self.value.weight
03/27 11:59:16 PM n: bert.encoder.layer.3.attention.self.value.bias
03/27 11:59:16 PM n: bert.encoder.layer.3.attention.output.dense.weight
03/27 11:59:16 PM n: bert.encoder.layer.3.attention.output.dense.bias
03/27 11:59:16 PM n: bert.encoder.layer.3.attention.output.LayerNorm.weight
03/27 11:59:16 PM n: bert.encoder.layer.3.attention.output.LayerNorm.bias
03/27 11:59:16 PM n: bert.encoder.layer.3.intermediate.dense.weight
03/27 11:59:16 PM n: bert.encoder.layer.3.intermediate.dense.bias
03/27 11:59:16 PM n: bert.encoder.layer.3.output.dense.weight
03/27 11:59:16 PM n: bert.encoder.layer.3.output.dense.bias
03/27 11:59:16 PM n: bert.encoder.layer.3.output.LayerNorm.weight
03/27 11:59:16 PM n: bert.encoder.layer.3.output.LayerNorm.bias
03/27 11:59:16 PM n: bert.pooler.dense.weight
03/27 11:59:16 PM n: bert.pooler.dense.bias
03/27 11:59:16 PM n: classifier.weight
03/27 11:59:16 PM n: classifier.bias
03/27 11:59:16 PM n: fit_dense.weight
03/27 11:59:16 PM n: fit_dense.bias
03/27 11:59:16 PM Total parameters: 14591258
Epoch:   0%|          | 0/3 [00:00<?, ?it/s]      /w/331/adeemj/csc2516_proj/Pretrained-Language-Model/TinyBERT/transformer/optimization.py:275: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other) [00:00<?, ?it/s]
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1485.)
  next_m.mul_(beta1).add_(1 - beta1, grad)



Iteration:   8%|8         | 43/535 [00:07<01:18,  6.28it/s]
03/27 11:59:24 PM ***** Running evaluation *****
03/27 11:59:24 PM   Epoch = 0 iter 49 step
03/27 11:59:24 PM   Num examples = 1043
03/27 11:59:24 PM   Batch size = 32
03/27 11:59:25 PM ***** Eval results *****
03/27 11:59:25 PM   acc = 0.7372962607861937
03/27 11:59:25 PM   att_loss = 0.0
03/27 11:59:25 PM   cls_loss = 0.33885330569987393
03/27 11:59:25 PM   eval_loss = 0.6491988933447636
03/27 11:59:25 PM   global_step = 49
03/27 11:59:25 PM   loss = 0.33885330569987393
03/27 11:59:25 PM   mcc = 0.30824938608195934
03/27 11:59:25 PM   rep_loss = 0.0
Iteration:   9%|8         | 48/535 [00:08<01:17,  6.32it/s]




Iteration:  18%|#8        | 98/535 [00:17<01:09,  6.29it/s]
03/27 11:59:33 PM ***** Running evaluation *****
03/27 11:59:33 PM   Epoch = 0 iter 99 step
03/27 11:59:33 PM   Num examples = 1043
03/27 11:59:33 PM   Batch size = 32
03/27 11:59:34 PM ***** Eval results *****
03/27 11:59:34 PM   acc = 0.7344199424736337
03/27 11:59:34 PM   att_loss = 0.0
03/27 11:59:34 PM   cls_loss = 0.3238991962538825
03/27 11:59:34 PM   eval_loss = 0.5843693261796777
03/27 11:59:34 PM   global_step = 99
03/27 11:59:34 PM   loss = 0.3238991962538825
03/27 11:59:34 PM   mcc = 0.2978314478991522
03/27 11:59:34 PM   rep_loss = 0.0



Iteration:  27%|##7       | 145/535 [00:25<01:01,  6.31it/s]
03/27 11:59:42 PM ***** Running evaluation *****
03/27 11:59:42 PM   Epoch = 0 iter 149 step
03/27 11:59:42 PM   Num examples = 1043
03/27 11:59:42 PM   Batch size = 32
03/27 11:59:43 PM ***** Eval results *****
03/27 11:59:43 PM   acc = 0.7372962607861937
03/27 11:59:43 PM   att_loss = 0.0
03/27 11:59:43 PM   cls_loss = 0.31266469303393524
03/27 11:59:43 PM   eval_loss = 0.5605835589495572
03/27 11:59:43 PM   global_step = 149
03/27 11:59:43 PM   loss = 0.31266469303393524
03/27 11:59:43 PM   mcc = 0.3237326020252071
03/27 11:59:43 PM   rep_loss = 0.0
Iteration:  28%|##7       | 148/535 [00:25<01:01,  6.32it/s]



Iteration:  37%|###7      | 198/535 [00:35<00:53,  6.29it/s]
Evaluating:  18%|█▊        | 6/33 [00:00<00:00, 55.42it/s]
03/27 11:59:51 PM ***** Running evaluation *****
03/27 11:59:51 PM   Epoch = 0 iter 199 step
03/27 11:59:51 PM   Num examples = 1043
03/27 11:59:51 PM   Batch size = 32
03/27 11:59:52 PM ***** Eval results *****
03/27 11:59:52 PM   acc = 0.7238734419942474
03/27 11:59:52 PM   att_loss = 0.0
03/27 11:59:52 PM   cls_loss = 0.30440946844354944
03/27 11:59:52 PM   eval_loss = 0.5606941246625149
03/27 11:59:52 PM   global_step = 199
03/27 11:59:52 PM   loss = 0.30440946844354944
03/27 11:59:52 PM   mcc = 0.316123487599861




Iteration:  46%|####5     | 246/535 [00:43<00:46,  6.26it/s]
03/28 12:00:00 AM ***** Running evaluation *****
03/28 12:00:00 AM   Epoch = 0 iter 249 step
03/28 12:00:00 AM   Num examples = 1043
03/28 12:00:00 AM   Batch size = 32
03/28 12:00:00 AM ***** Eval results *****
03/28 12:00:00 AM   acc = 0.7363374880153404
03/28 12:00:00 AM   att_loss = 0.0
03/28 12:00:00 AM   cls_loss = 0.2990471514832064
03/28 12:00:00 AM   eval_loss = 0.5547104152766141
03/28 12:00:00 AM   global_step = 249
03/28 12:00:00 AM   loss = 0.2990471514832064
03/28 12:00:00 AM   mcc = 0.32066729696834345
Iteration:  46%|####6     | 248/535 [00:43<00:45,  6.27it/s]



Iteration:  55%|#####4    | 293/535 [00:51<00:38,  6.27it/s]
03/28 12:00:08 AM ***** Running evaluation *****
03/28 12:00:08 AM   Epoch = 0 iter 299 step
03/28 12:00:08 AM   Num examples = 1043
03/28 12:00:08 AM   Batch size = 32
03/28 12:00:09 AM ***** Eval results *****
03/28 12:00:09 AM   acc = 0.7286673058485139
03/28 12:00:09 AM   att_loss = 0.0
03/28 12:00:09 AM   cls_loss = 0.2953180235664183
03/28 12:00:09 AM   eval_loss = 0.5561566036759
03/28 12:00:09 AM   global_step = 299
03/28 12:00:09 AM   loss = 0.2953180235664183
03/28 12:00:09 AM   mcc = 0.332634547752676
03/28 12:00:09 AM   rep_loss = 0.0
Iteration:  56%|#####5    | 298/535 [00:52<00:37,  6.27it/s]




Iteration:  65%|######4   | 347/535 [01:01<00:30,  6.22it/s]
03/28 12:00:18 AM ***** Running evaluation *****
03/28 12:00:18 AM   Epoch = 0 iter 349 step
03/28 12:00:18 AM   Num examples = 1043
03/28 12:00:18 AM   Batch size = 32
03/28 12:00:18 AM ***** Eval results *****
03/28 12:00:18 AM   acc = 0.7315436241610739
03/28 12:00:18 AM   att_loss = 0.0
03/28 12:00:18 AM   cls_loss = 0.2924519468173598
03/28 12:00:18 AM   eval_loss = 0.5577743857195883
03/28 12:00:18 AM   global_step = 349
03/28 12:00:18 AM   loss = 0.2924519468173598
03/28 12:00:18 AM   mcc = 0.2854756779127197
Iteration:  65%|######5   | 348/535 [01:01<00:29,  6.24it/s]



Iteration:  74%|#######3  | 394/535 [01:09<00:22,  6.27it/s]
03/28 12:00:26 AM ***** Running evaluation *****
03/28 12:00:26 AM   Epoch = 0 iter 399 step
03/28 12:00:26 AM   Num examples = 1043
03/28 12:00:26 AM   Batch size = 32
03/28 12:00:27 AM ***** Eval results *****
03/28 12:00:27 AM   acc = 0.7344199424736337
03/28 12:00:27 AM   att_loss = 0.0
03/28 12:00:27 AM   cls_loss = 0.29057223874524724
03/28 12:00:27 AM   eval_loss = 0.5500271139722882
03/28 12:00:27 AM   global_step = 399
03/28 12:00:27 AM   loss = 0.29057223874524724
03/28 12:00:27 AM   mcc = 0.31601258155007883
Iteration:  74%|#######4  | 398/535 [01:10<00:21,  6.26it/s]



Iteration:  82%|########2 | 440/535 [01:17<00:15,  6.28it/s]
03/28 12:00:35 AM ***** Running evaluation *****
03/28 12:00:35 AM   Epoch = 0 iter 449 step
03/28 12:00:35 AM   Num examples = 1043
Iteration:  84%|########3 | 448/535 [01:18<00:13,  6.26it/s]
Iteration:  84%|########3 | 449/535 [01:19<00:29,  2.92it/s]
03/28 12:00:35 AM ***** Eval results *****
03/28 12:00:35 AM   acc = 0.7305848513902206
03/28 12:00:35 AM   att_loss = 0.0
03/28 12:00:35 AM   cls_loss = 0.2886512992044865
03/28 12:00:35 AM   eval_loss = 0.5484534592339487
03/28 12:00:35 AM   global_step = 449
03/28 12:00:35 AM   loss = 0.2886512992044865
03/28 12:00:35 AM   mcc = 0.30932848813727776



Iteration:  93%|#########3| 498/535 [01:27<00:05,  6.27it/s]
Evaluating:   0%|          | 0/33 [00:00<?, ?it/s]
03/28 12:00:43 AM ***** Running evaluation *****
03/28 12:00:43 AM   Epoch = 0 iter 499 step
03/28 12:00:43 AM   Num examples = 1043
03/28 12:00:43 AM   Batch size = 32
03/28 12:00:44 AM ***** Eval results *****
03/28 12:00:44 AM   acc = 0.7334611697027804
03/28 12:00:44 AM   att_loss = 0.0
03/28 12:00:44 AM   cls_loss = 0.2868491392993258
03/28 12:00:44 AM   eval_loss = 0.5457829697565599
03/28 12:00:44 AM   global_step = 499
03/28 12:00:44 AM   loss = 0.2868491392993258
03/28 12:00:44 AM   mcc = 0.31927567720124567



Epoch:  33%|███▎      | 1/3 [01:33<03:07, 93.76s/it].25it/s]
Iteration:   2%|2         | 12/535 [00:01<01:23,  6.26it/s]
03/28 12:00:52 AM ***** Running evaluation *****
03/28 12:00:52 AM   Epoch = 1 iter 549 step
03/28 12:00:52 AM   Num examples = 1043
03/28 12:00:52 AM   Batch size = 32
03/28 12:00:53 AM ***** Eval results *****
03/28 12:00:53 AM   acc = 0.7363374880153404
03/28 12:00:53 AM   att_loss = 0.0
03/28 12:00:53 AM   cls_loss = 0.26884395877520245
03/28 12:00:53 AM   eval_loss = 0.5466778233195796
03/28 12:00:53 AM   global_step = 549
03/28 12:00:53 AM   loss = 0.26884395877520245
03/28 12:00:53 AM   mcc = 0.30952433026244985
Iteration:   3%|2         | 14/535 [00:02<01:23,  6.23it/s]



Iteration:  11%|#         | 58/535 [00:09<01:15,  6.28it/s]
03/28 12:01:01 AM ***** Running evaluation *****
03/28 12:01:01 AM   Epoch = 1 iter 599 step
03/28 12:01:01 AM   Num examples = 1043
Iteration:  12%|#1        | 64/535 [00:10<01:15,  6.27it/s]
Evaluating:  91%|█████████ | 30/33 [00:00<00:00, 54.59it/s]
03/28 12:01:01 AM ***** Eval results *****
03/28 12:01:01 AM   acc = 0.7430488974113135
03/28 12:01:01 AM   att_loss = 0.0
03/28 12:01:01 AM   cls_loss = 0.27439132309876957
03/28 12:01:01 AM   eval_loss = 0.5428797250444238
03/28 12:01:01 AM   global_step = 599
03/28 12:01:01 AM   loss = 0.27439132309876957
03/28 12:01:01 AM   mcc = 0.33993010293244547
03/28 12:01:01 AM   rep_loss = 0.0




Iteration:  21%|##1       | 113/535 [00:19<01:07,  6.25it/s]
03/28 12:01:10 AM ***** Running evaluation *****
03/28 12:01:10 AM   Epoch = 1 iter 649 step
03/28 12:01:10 AM   Num examples = 1043
03/28 12:01:10 AM   Batch size = 32
03/28 12:01:11 AM ***** Eval results *****
03/28 12:01:11 AM   acc = 0.738255033557047
03/28 12:01:11 AM   att_loss = 0.0
03/28 12:01:11 AM   cls_loss = 0.2732378377862599
03/28 12:01:11 AM   eval_loss = 0.5440557617129702
03/28 12:01:11 AM   global_step = 649
03/28 12:01:11 AM   loss = 0.2732378377862599
03/28 12:01:11 AM   mcc = 0.3366806107924566
Iteration:  21%|##1       | 114/535 [00:20<01:07,  6.24it/s]



Iteration:  30%|##9       | 159/535 [00:27<01:00,  6.26it/s]
03/28 12:01:19 AM ***** Running evaluation *****
03/28 12:01:19 AM   Epoch = 1 iter 699 step
03/28 12:01:19 AM   Num examples = 1043
03/28 12:01:19 AM   Batch size = 32
03/28 12:01:19 AM ***** Eval results *****
03/28 12:01:19 AM   acc = 0.7440076701821668
03/28 12:01:19 AM   att_loss = 0.0
03/28 12:01:19 AM   cls_loss = 0.2725823098962957
03/28 12:01:19 AM   eval_loss = 0.5451390192364202
03/28 12:01:19 AM   global_step = 699
03/28 12:01:19 AM   loss = 0.2725823098962957
03/28 12:01:19 AM   mcc = 0.334869093311565
Iteration:  31%|###       | 164/535 [00:28<00:59,  6.23it/s]



Iteration:  38%|###8      | 205/535 [00:35<00:52,  6.25it/s]
03/28 12:01:27 AM ***** Running evaluation *****
03/28 12:01:27 AM   Epoch = 1 iter 749 step
03/28 12:01:27 AM   Num examples = 1043
Iteration:  40%|####      | 214/535 [00:37<00:51,  6.25it/s]
Evaluating:  73%|███████▎  | 24/33 [00:00<00:00, 53.07it/s]
03/28 12:01:28 AM ***** Eval results *****
03/28 12:01:28 AM   acc = 0.7459252157238735
03/28 12:01:28 AM   att_loss = 0.0
03/28 12:01:28 AM   cls_loss = 0.27253518166930174
03/28 12:01:28 AM   eval_loss = 0.5452113043178212
03/28 12:01:28 AM   global_step = 749
03/28 12:01:28 AM   loss = 0.27253518166930174
03/28 12:01:28 AM   mcc = 0.3459141688557483
03/28 12:01:28 AM   rep_loss = 0.0




Iteration:  49%|####8     | 260/535 [00:46<00:44,  6.24it/s]
03/28 12:01:36 AM ***** Running evaluation *****
03/28 12:01:36 AM   Epoch = 1 iter 799 step
03/28 12:01:36 AM   Num examples = 1043
03/28 12:01:36 AM   Batch size = 32
03/28 12:01:37 AM ***** Eval results *****
03/28 12:01:37 AM   acc = 0.738255033557047
03/28 12:01:37 AM   att_loss = 0.0
03/28 12:01:37 AM   cls_loss = 0.27158926185571924
03/28 12:01:37 AM   eval_loss = 0.5469632383548853
03/28 12:01:37 AM   global_step = 799
03/28 12:01:37 AM   loss = 0.27158926185571924
03/28 12:01:37 AM   mcc = 0.33508616900126137
Iteration:  49%|####9     | 264/535 [00:46<00:43,  6.25it/s]



Iteration:  57%|#####7    | 306/535 [00:54<00:36,  6.25it/s]
03/28 12:01:45 AM ***** Running evaluation *****
03/28 12:01:45 AM   Epoch = 1 iter 849 step
03/28 12:01:45 AM   Num examples = 1043
Iteration:  59%|#####8    | 314/535 [00:55<00:35,  6.24it/s]
Evaluating:  91%|█████████ | 30/33 [00:00<00:00, 54.46it/s]
03/28 12:01:46 AM ***** Eval results *****
03/28 12:01:46 AM   acc = 0.7440076701821668
03/28 12:01:46 AM   att_loss = 0.0
03/28 12:01:46 AM   cls_loss = 0.27176482951830305
03/28 12:01:46 AM   eval_loss = 0.5467509537032156
03/28 12:01:46 AM   global_step = 849
03/28 12:01:46 AM   loss = 0.27176482951830305
03/28 12:01:46 AM   mcc = 0.32914451996870747



Iteration:  68%|######8   | 364/535 [01:03<00:27,  6.26it/s]
Evaluating:   0%|          | 0/33 [00:00<?, ?it/s]
03/28 12:01:54 AM ***** Running evaluation *****
03/28 12:01:54 AM   Epoch = 1 iter 899 step
03/28 12:01:54 AM   Num examples = 1043
03/28 12:01:54 AM   Batch size = 32
03/28 12:01:54 AM ***** Eval results *****
03/28 12:01:54 AM   acc = 0.7411313518696069
03/28 12:01:54 AM   att_loss = 0.0
03/28 12:01:54 AM   cls_loss = 0.27193395005513543
03/28 12:01:54 AM   eval_loss = 0.5465984344482422
03/28 12:01:54 AM   global_step = 899
03/28 12:01:54 AM   loss = 0.27193395005513543
03/28 12:01:54 AM   mcc = 0.32940166149822514




Iteration:  77%|#######6  | 411/535 [01:12<00:19,  6.23it/s]
03/28 12:02:02 AM ***** Running evaluation *****
03/28 12:02:02 AM   Epoch = 1 iter 949 step
03/28 12:02:02 AM   Num examples = 1043
03/28 12:02:02 AM   Batch size = 32
03/28 12:02:03 AM ***** Eval results *****
03/28 12:02:03 AM   acc = 0.7392138063279002
03/28 12:02:03 AM   att_loss = 0.0
03/28 12:02:03 AM   cls_loss = 0.27177377160055094
03/28 12:02:03 AM   eval_loss = 0.5478207956660878
03/28 12:02:03 AM   global_step = 949
03/28 12:02:03 AM   loss = 0.27177377160055094
03/28 12:02:03 AM   mcc = 0.33346867625245996
Iteration:  77%|#######7  | 414/535 [01:12<00:19,  6.24it/s]



Iteration:  85%|########5 | 457/535 [01:20<00:12,  6.22it/s]
03/28 12:02:11 AM ***** Running evaluation *****
03/28 12:02:11 AM   Epoch = 1 iter 999 step
03/28 12:02:11 AM   Num examples = 1043
Iteration:  87%|########6 | 464/535 [01:21<00:11,  6.24it/s]
Iteration:  87%|########7 | 466/535 [01:22<00:19,  3.46it/s]
03/28 12:02:12 AM ***** Eval results *****
03/28 12:02:12 AM   acc = 0.7411313518696069
03/28 12:02:12 AM   att_loss = 0.0
03/28 12:02:12 AM   cls_loss = 0.2714641381976425
03/28 12:02:12 AM   eval_loss = 0.5458868010477587
03/28 12:02:12 AM   global_step = 999
03/28 12:02:12 AM   loss = 0.2714641381976425
03/28 12:02:12 AM   mcc = 0.3282176894264508



Iteration:  96%|#########6| 514/535 [01:29<00:03,  6.25it/s]
Evaluating:  18%|█▊        | 6/33 [00:00<00:00, 54.62it/s]
03/28 12:02:20 AM ***** Running evaluation *****
03/28 12:02:20 AM   Epoch = 1 iter 1049 step
03/28 12:02:20 AM   Num examples = 1043
03/28 12:02:20 AM   Batch size = 32
03/28 12:02:20 AM ***** Eval results *****
03/28 12:02:20 AM   acc = 0.7420901246404602
03/28 12:02:20 AM   att_loss = 0.0
03/28 12:02:20 AM   cls_loss = 0.2715712700075316
03/28 12:02:20 AM   eval_loss = 0.5444475105314543
03/28 12:02:20 AM   global_step = 1049
03/28 12:02:20 AM   loss = 0.2715712700075316
03/28 12:02:20 AM   mcc = 0.3319045664297391

Epoch:  67%|██████▋   | 2/3 [03:07<01:33, 93.68s/it].22it/s]


Iteration:   5%|5         | 28/535 [00:04<01:21,  6.22it/s]
03/28 12:02:28 AM ***** Running evaluation *****
03/28 12:02:28 AM   Epoch = 2 iter 1099 step
03/28 12:02:28 AM   Num examples = 1043
03/28 12:02:28 AM   Batch size = 32
03/28 12:02:29 AM ***** Eval results *****
03/28 12:02:29 AM   acc = 0.7267497603068073
03/28 12:02:29 AM   att_loss = 0.0
03/28 12:02:29 AM   cls_loss = 0.26899741301613467
03/28 12:02:29 AM   eval_loss = 0.5450800016070857
03/28 12:02:29 AM   global_step = 1099
03/28 12:02:29 AM   loss = 0.26899741301613467
03/28 12:02:29 AM   mcc = 0.30140571370330893
Iteration:   6%|5         | 30/535 [00:04<01:21,  6.22it/s]



Iteration:  14%|#3        | 74/535 [00:12<01:13,  6.28it/s]
03/28 12:02:37 AM ***** Running evaluation *****
03/28 12:02:37 AM   Epoch = 2 iter 1149 step
03/28 12:02:37 AM   Num examples = 1043
Iteration:  15%|#4        | 80/535 [00:13<01:12,  6.27it/s]
Iteration:  16%|#5        | 83/535 [00:14<01:53,  3.98it/s]
03/28 12:02:37 AM ***** Eval results *****
03/28 12:02:37 AM   acc = 0.7401725790987536
03/28 12:02:37 AM   att_loss = 0.0
03/28 12:02:37 AM   cls_loss = 0.2713141088132505
03/28 12:02:37 AM   eval_loss = 0.5428620911005771
03/28 12:02:37 AM   global_step = 1149
03/28 12:02:37 AM   loss = 0.2713141088132505
03/28 12:02:37 AM   mcc = 0.32947359113341773



Iteration:  24%|##4       | 130/535 [00:22<01:04,  6.24it/s]
Evaluating:  55%|█████▍    | 18/33 [00:00<00:00, 54.57it/s]
03/28 12:02:45 AM ***** Running evaluation *****
03/28 12:02:45 AM   Epoch = 2 iter 1199 step
03/28 12:02:45 AM   Num examples = 1043
03/28 12:02:45 AM   Batch size = 32
03/28 12:02:46 AM ***** Eval results *****
03/28 12:02:46 AM   acc = 0.7392138063279002
03/28 12:02:46 AM   att_loss = 0.0
03/28 12:02:46 AM   cls_loss = 0.27012854678030235
03/28 12:02:46 AM   eval_loss = 0.5425491766496138
03/28 12:02:46 AM   global_step = 1199
03/28 12:02:46 AM   loss = 0.27012854678030235
03/28 12:02:46 AM   mcc = 0.3284361237784734




Iteration:  33%|###3      | 179/535 [00:30<00:57,  6.24it/s]
03/28 12:02:54 AM ***** Running evaluation *****
03/28 12:02:54 AM   Epoch = 2 iter 1249 step
03/28 12:02:54 AM   Num examples = 1043
03/28 12:02:54 AM   Batch size = 32
03/28 12:02:55 AM ***** Eval results *****
03/28 12:02:55 AM   acc = 0.7401725790987536
03/28 12:02:55 AM   att_loss = 0.0
03/28 12:02:55 AM   cls_loss = 0.27058869221592474
03/28 12:02:55 AM   eval_loss = 0.5433466895060106
03/28 12:02:55 AM   global_step = 1249
03/28 12:02:55 AM   loss = 0.27058869221592474
03/28 12:02:55 AM   mcc = 0.3335779251123227
Iteration:  34%|###3      | 180/535 [00:30<00:56,  6.24it/s]



Iteration:  42%|####2     | 225/535 [00:38<00:49,  6.23it/s]
03/28 12:03:03 AM ***** Running evaluation *****
03/28 12:03:03 AM   Epoch = 2 iter 1299 step
03/28 12:03:03 AM   Num examples = 1043
Iteration:  43%|####2     | 230/535 [00:39<00:48,  6.23it/s]
Iteration:  44%|####3     | 234/535 [00:40<01:07,  4.46it/s]
03/28 12:03:03 AM ***** Eval results *****
03/28 12:03:03 AM   acc = 0.7315436241610739
03/28 12:03:03 AM   att_loss = 0.0
03/28 12:03:03 AM   cls_loss = 0.27037943964138694
03/28 12:03:03 AM   eval_loss = 0.5428473850091299
03/28 12:03:03 AM   global_step = 1299
03/28 12:03:03 AM   loss = 0.27037943964138694
03/28 12:03:03 AM   mcc = 0.3123814262740551



Iteration:  52%|#####2    | 280/535 [00:47<00:40,  6.22it/s]
Evaluating:  73%|███████▎  | 24/33 [00:00<00:00, 54.30it/s]
03/28 12:03:11 AM ***** Running evaluation *****
03/28 12:03:11 AM   Epoch = 2 iter 1349 step
03/28 12:03:11 AM   Num examples = 1043
03/28 12:03:11 AM   Batch size = 32
03/28 12:03:12 AM ***** Eval results *****
03/28 12:03:12 AM   acc = 0.7420901246404602
03/28 12:03:12 AM   att_loss = 0.0
03/28 12:03:12 AM   cls_loss = 0.2703264039076096
03/28 12:03:12 AM   eval_loss = 0.541332028128884
03/28 12:03:12 AM   global_step = 1349
03/28 12:03:12 AM   loss = 0.2703264039076096
03/28 12:03:12 AM   mcc = 0.3355929137326878




Iteration:  61%|######1   | 329/535 [00:56<00:33,  6.20it/s]
03/28 12:03:20 AM ***** Running evaluation *****
03/28 12:03:20 AM   Epoch = 2 iter 1399 step
03/28 12:03:20 AM   Num examples = 1043
03/28 12:03:20 AM   Batch size = 32
03/28 12:03:21 AM ***** Eval results *****
03/28 12:03:21 AM   acc = 0.7449664429530202
03/28 12:03:21 AM   att_loss = 0.0
03/28 12:03:21 AM   cls_loss = 0.27068635866361085
03/28 12:03:21 AM   eval_loss = 0.5412637790044149
03/28 12:03:21 AM   global_step = 1399
03/28 12:03:21 AM   loss = 0.27068635866361085
03/28 12:03:21 AM   mcc = 0.34114287267917587
Iteration:  62%|######1   | 330/535 [00:56<00:33,  6.21it/s]



Iteration:  70%|#######   | 376/535 [01:04<00:25,  6.23it/s]
03/28 12:03:29 AM ***** Running evaluation *****
03/28 12:03:29 AM   Epoch = 2 iter 1449 step
03/28 12:03:29 AM   Num examples = 1043
03/28 12:03:29 AM   Batch size = 32
03/28 12:03:29 AM ***** Eval results *****
03/28 12:03:29 AM   acc = 0.7430488974113135
03/28 12:03:29 AM   att_loss = 0.0
03/28 12:03:29 AM   cls_loss = 0.27033733684090494
03/28 12:03:29 AM   eval_loss = 0.5413770937558376
03/28 12:03:29 AM   global_step = 1449
03/28 12:03:29 AM   loss = 0.27033733684090494
03/28 12:03:29 AM   mcc = 0.3386383515722791
Iteration:  71%|#######1  | 380/535 [01:05<00:24,  6.23it/s]



Iteration:  79%|#######8  | 422/535 [01:12<00:18,  6.22it/s]
03/28 12:03:37 AM ***** Running evaluation *****
03/28 12:03:37 AM   Epoch = 2 iter 1499 step
03/28 12:03:37 AM   Num examples = 1043
Iteration:  80%|########  | 430/535 [01:13<00:16,  6.21it/s]
Evaluating:  91%|█████████ | 30/33 [00:00<00:00, 54.24it/s]
03/28 12:03:38 AM ***** Eval results *****
03/28 12:03:38 AM   acc = 0.7411313518696069
03/28 12:03:38 AM   att_loss = 0.0
03/28 12:03:38 AM   cls_loss = 0.27028860369580526
03/28 12:03:38 AM   eval_loss = 0.5417198331067057
03/28 12:03:38 AM   global_step = 1499
03/28 12:03:38 AM   loss = 0.27028860369580526
03/28 12:03:38 AM   mcc = 0.3352124333269541




Iteration:  90%|########9 | 480/535 [01:22<00:08,  6.23it/s]
03/28 12:03:46 AM ***** Running evaluation *****
03/28 12:03:46 AM   Epoch = 2 iter 1549 step
03/28 12:03:46 AM   Num examples = 1043
03/28 12:03:46 AM   Batch size = 32
03/28 12:03:47 AM ***** Eval results *****
03/28 12:03:47 AM   acc = 0.7411313518696069
03/28 12:03:47 AM   att_loss = 0.0
03/28 12:03:47 AM   cls_loss = 0.2702227036261509
03/28 12:03:47 AM   eval_loss = 0.5417696120160999
03/28 12:03:47 AM   global_step = 1549
03/28 12:03:47 AM   loss = 0.2702227036261509
03/28 12:03:47 AM   mcc = 0.3352124333269541
03/28 12:03:47 AM   rep_loss = 0.0



Iteration:  98%|#########8| 526/535 [01:30<00:01,  6.23it/s]
03/28 12:03:55 AM ***** Running evaluation *****
03/28 12:03:55 AM   Epoch = 2 iter 1599 step
03/28 12:03:55 AM   Num examples = 1043
03/28 12:03:55 AM   Batch size = 32
03/28 12:03:55 AM ***** Eval results *****
03/28 12:03:55 AM   acc = 0.7449664429530202
03/28 12:03:55 AM   att_loss = 0.0
03/28 12:03:55 AM   cls_loss = 0.2700506564363023
03/28 12:03:55 AM   eval_loss = 0.5416369564605482
03/28 12:03:55 AM   global_step = 1599
03/28 12:03:55 AM   loss = 0.2700506564363023
03/28 12:03:55 AM   mcc = 0.34470146250315514
Iteration: 100%|##########| 535/535 [01:32<00:00,  5.78it/s]
Epoch: 100%|██████████| 3/3 [04:39<00:00, 93.29s/it].47it/s]