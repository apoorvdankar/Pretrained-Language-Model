03/27 07:37:42 PM device: cuda n_gpu: 1
USING KL ATTN LOSS WITH WEIGHT =  0.01
03/27 07:37:42 PM Writing example 0 of 8551
03/27 07:37:42 PM *** Example ***
03/27 07:37:42 PM guid: train-0
03/27 07:37:42 PM tokens: [CLS] our friends won ' t buy this analysis , let alone the next one we propose . [SEP]
03/27 07:37:42 PM input_ids: 101 2256 2814 2180 1005 1056 4965 2023 4106 1010 2292 2894 1996 2279 2028 2057 16599 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/27 07:37:42 PM input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/27 07:37:42 PM segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/27 07:37:42 PM label: 1
03/27 07:37:42 PM label_id: 1
03/27 07:37:43 PM Writing example 0 of 1043
03/27 07:37:43 PM *** Example ***
03/27 07:37:43 PM guid: dev-0
03/27 07:37:43 PM tokens: [CLS] the sailors rode the breeze clear of the rocks . [SEP]
03/27 07:37:43 PM input_ids: 101 1996 11279 8469 1996 9478 3154 1997 1996 5749 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/27 07:37:43 PM input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/27 07:37:43 PM segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/27 07:37:43 PM label: 1
03/27 07:37:43 PM label_id: 1
03/27 07:37:43 PM loading archive file /w/331/adeemj/csc2516_proj/models/CoLA/models--textattack--bert-base-uncased-CoLA/snapshots/5fed03dd6bc5f0b40e86cb04cd1a16eb404ba391/
03/27 07:37:43 PM Model config {
  "architectures": [
    "BertForSequenceClassification"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "cola",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pre_trained": "",
  "training": "",
  "type_vocab_size": 2,
  "vocab_size": 30522
}
03/27 07:37:45 PM Loading model /w/331/adeemj/csc2516_proj/models/CoLA/models--textattack--bert-base-uncased-CoLA/snapshots/5fed03dd6bc5f0b40e86cb04cd1a16eb404ba391/pytorch_model.bin
03/27 07:37:45 PM loading model...
03/27 07:37:45 PM done!
03/27 07:37:45 PM Weights of TinyBertForSequenceClassification not initialized from pretrained model: ['fit_dense.weight', 'fit_dense.bias']
03/27 07:37:45 PM loading archive file /w/331/adeemj/csc2516_proj/models/models--huawei-noah--TinyBERT_General_4L_312D/snapshots/34707a33cd59a94ecde241ac209bf35103691b43/
03/27 07:37:45 PM Model config {
  "attention_probs_dropout_prob": 0.1,
  "cell": {},
  "emb_size": 312,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 312,
  "initializer_range": 0.02,
  "intermediate_size": 1200,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 4,
  "pre_trained": "",
  "structure": [],
  "training": "",
  "type_vocab_size": 2,
  "vocab_size": 30522
}
03/27 07:37:45 PM Loading model /w/331/adeemj/csc2516_proj/models/models--huawei-noah--TinyBERT_General_4L_312D/snapshots/34707a33cd59a94ecde241ac209bf35103691b43/pytorch_model.bin
03/27 07:37:45 PM loading model...
03/27 07:37:45 PM done!
03/27 07:37:45 PM Weights of TinyBertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias', 'fit_dense.weight', 'fit_dense.bias']
03/27 07:37:45 PM Weights from pretrained model not used in TinyBertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'fit_denses.0.weight', 'fit_denses.0.bias', 'fit_denses.1.weight', 'fit_denses.1.bias', 'fit_denses.2.weight', 'fit_denses.2.bias', 'fit_denses.3.weight', 'fit_denses.3.bias', 'fit_denses.4.weight', 'fit_denses.4.bias']
03/27 07:37:45 PM ***** Running training *****
03/27 07:37:45 PM   Num examples = 8551
03/27 07:37:45 PM   Batch size = 32
03/27 07:37:45 PM   Num steps = 8010
03/27 07:37:45 PM n: bert.embeddings.word_embeddings.weight
03/27 07:37:45 PM n: bert.embeddings.position_embeddings.weight
03/27 07:37:45 PM n: bert.embeddings.token_type_embeddings.weight
03/27 07:37:45 PM n: bert.embeddings.LayerNorm.weight
03/27 07:37:45 PM n: bert.embeddings.LayerNorm.bias
03/27 07:37:45 PM n: bert.encoder.layer.0.attention.self.query.weight
03/27 07:37:45 PM n: bert.encoder.layer.0.attention.self.query.bias
03/27 07:37:45 PM n: bert.encoder.layer.0.attention.self.key.weight
03/27 07:37:45 PM n: bert.encoder.layer.0.attention.self.key.bias
03/27 07:37:45 PM n: bert.encoder.layer.0.attention.self.value.weight
03/27 07:37:45 PM n: bert.encoder.layer.0.attention.self.value.bias
03/27 07:37:45 PM n: bert.encoder.layer.0.attention.output.dense.weight
03/27 07:37:45 PM n: bert.encoder.layer.0.attention.output.dense.bias
03/27 07:37:45 PM n: bert.encoder.layer.0.attention.output.LayerNorm.weight
03/27 07:37:45 PM n: bert.encoder.layer.0.attention.output.LayerNorm.bias
03/27 07:37:45 PM n: bert.encoder.layer.0.intermediate.dense.weight
03/27 07:37:45 PM n: bert.encoder.layer.0.intermediate.dense.bias
03/27 07:37:45 PM n: bert.encoder.layer.0.output.dense.weight
03/27 07:37:45 PM n: bert.encoder.layer.0.output.dense.bias
03/27 07:37:45 PM n: bert.encoder.layer.0.output.LayerNorm.weight
03/27 07:37:45 PM n: bert.encoder.layer.0.output.LayerNorm.bias
03/27 07:37:45 PM n: bert.encoder.layer.1.attention.self.query.weight
03/27 07:37:45 PM n: bert.encoder.layer.1.attention.self.query.bias
03/27 07:37:45 PM n: bert.encoder.layer.1.attention.self.key.weight
03/27 07:37:45 PM n: bert.encoder.layer.1.attention.self.key.bias
03/27 07:37:45 PM n: bert.encoder.layer.1.attention.self.value.weight
03/27 07:37:45 PM n: bert.encoder.layer.1.attention.self.value.bias
03/27 07:37:45 PM n: bert.encoder.layer.1.attention.output.dense.weight
03/27 07:37:45 PM n: bert.encoder.layer.1.attention.output.dense.bias
03/27 07:37:45 PM n: bert.encoder.layer.1.attention.output.LayerNorm.weight
03/27 07:37:45 PM n: bert.encoder.layer.1.attention.output.LayerNorm.bias
03/27 07:37:45 PM n: bert.encoder.layer.1.intermediate.dense.weight
03/27 07:37:45 PM n: bert.encoder.layer.1.intermediate.dense.bias
03/27 07:37:45 PM n: bert.encoder.layer.1.output.dense.weight
03/27 07:37:45 PM n: bert.encoder.layer.1.output.dense.bias
03/27 07:37:45 PM n: bert.encoder.layer.1.output.LayerNorm.weight
03/27 07:37:45 PM n: bert.encoder.layer.1.output.LayerNorm.bias
03/27 07:37:45 PM n: bert.encoder.layer.2.attention.self.query.weight
03/27 07:37:45 PM n: bert.encoder.layer.2.attention.self.query.bias
03/27 07:37:45 PM n: bert.encoder.layer.2.attention.self.key.weight
03/27 07:37:45 PM n: bert.encoder.layer.2.attention.self.key.bias
03/27 07:37:45 PM n: bert.encoder.layer.2.attention.self.value.weight
03/27 07:37:45 PM n: bert.encoder.layer.2.attention.self.value.bias
03/27 07:37:45 PM n: bert.encoder.layer.2.attention.output.dense.weight
03/27 07:37:45 PM n: bert.encoder.layer.2.attention.output.dense.bias
03/27 07:37:45 PM n: bert.encoder.layer.2.attention.output.LayerNorm.weight
03/27 07:37:45 PM n: bert.encoder.layer.2.attention.output.LayerNorm.bias
03/27 07:37:45 PM n: bert.encoder.layer.2.intermediate.dense.weight
03/27 07:37:45 PM n: bert.encoder.layer.2.intermediate.dense.bias
03/27 07:37:45 PM n: bert.encoder.layer.2.output.dense.weight
03/27 07:37:45 PM n: bert.encoder.layer.2.output.dense.bias
03/27 07:37:45 PM n: bert.encoder.layer.2.output.LayerNorm.weight
03/27 07:37:45 PM n: bert.encoder.layer.2.output.LayerNorm.bias
03/27 07:37:45 PM n: bert.encoder.layer.3.attention.self.query.weight
03/27 07:37:45 PM n: bert.encoder.layer.3.attention.self.query.bias
03/27 07:37:45 PM n: bert.encoder.layer.3.attention.self.key.weight
03/27 07:37:45 PM n: bert.encoder.layer.3.attention.self.key.bias
03/27 07:37:45 PM n: bert.encoder.layer.3.attention.self.value.weight
03/27 07:37:45 PM n: bert.encoder.layer.3.attention.self.value.bias
03/27 07:37:45 PM n: bert.encoder.layer.3.attention.output.dense.weight
03/27 07:37:45 PM n: bert.encoder.layer.3.attention.output.dense.bias
03/27 07:37:45 PM n: bert.encoder.layer.3.attention.output.LayerNorm.weight
03/27 07:37:45 PM n: bert.encoder.layer.3.attention.output.LayerNorm.bias
03/27 07:37:45 PM n: bert.encoder.layer.3.intermediate.dense.weight
03/27 07:37:45 PM n: bert.encoder.layer.3.intermediate.dense.bias
03/27 07:37:45 PM n: bert.encoder.layer.3.output.dense.weight
03/27 07:37:45 PM n: bert.encoder.layer.3.output.dense.bias
03/27 07:37:45 PM n: bert.encoder.layer.3.output.LayerNorm.weight
03/27 07:37:45 PM n: bert.encoder.layer.3.output.LayerNorm.bias
03/27 07:37:45 PM n: bert.pooler.dense.weight
03/27 07:37:45 PM n: bert.pooler.dense.bias
03/27 07:37:45 PM n: classifier.weight
03/27 07:37:45 PM n: classifier.bias
03/27 07:37:45 PM n: fit_dense.weight
03/27 07:37:45 PM n: fit_dense.bias
03/27 07:37:45 PM Total parameters: 14591258
Epoch:   0%|          | 0/30 [00:00<?, ?it/s]




Iteration:  18%|#7        | 47/268 [00:09<00:44,  4.97it/s]
03/27 07:37:55 PM ***** Running evaluation *****
03/27 07:37:55 PM   Epoch = 0 iter 49 step
03/27 07:37:55 PM   Num examples = 1043
03/27 07:37:55 PM   Batch size = 32
03/27 07:37:55 PM ***** Eval results *****
03/27 07:37:55 PM   att_loss = 8.809167939789441
03/27 07:37:55 PM   cls_loss = 0.0
03/27 07:37:55 PM   global_step = 49
03/27 07:37:55 PM   loss = 10.371721092535525
03/27 07:37:55 PM   rep_loss = 1.5625531941044086






Iteration:  37%|###6      | 99/268 [00:21<01:09,  2.42it/s]
03/27 07:38:06 PM ***** Running evaluation *****
03/27 07:38:06 PM   Epoch = 0 iter 99 step
03/27 07:38:06 PM   Num examples = 1043
03/27 07:38:06 PM   Batch size = 32
03/27 07:38:06 PM ***** Eval results *****
03/27 07:38:06 PM   att_loss = 8.11006970839067
03/27 07:38:06 PM   cls_loss = 0.0
03/27 07:38:06 PM   global_step = 99
03/27 07:38:06 PM   loss = 9.42553767772636
03/27 07:38:06 PM   rep_loss = 1.3154680168989934





Iteration:  55%|#####5    | 148/268 [00:31<00:24,  4.90it/s]
03/27 07:38:17 PM ***** Running evaluation *****
03/27 07:38:17 PM   Epoch = 0 iter 149 step
03/27 07:38:17 PM   Num examples = 1043
03/27 07:38:17 PM   Batch size = 32
03/27 07:38:17 PM ***** Eval results *****
03/27 07:38:17 PM   att_loss = 7.770787786317352
03/27 07:38:17 PM   cls_loss = 0.0
03/27 07:38:17 PM   global_step = 149
03/27 07:38:17 PM   loss = 8.950733079206223
03/27 07:38:17 PM   rep_loss = 1.179945334892145





Iteration:  72%|#######2  | 194/268 [00:41<00:15,  4.86it/s]
03/27 07:38:27 PM ***** Running evaluation *****
03/27 07:38:27 PM   Epoch = 0 iter 199 step
03/27 07:38:27 PM   Num examples = 1043
03/27 07:38:27 PM   Batch size = 32
03/27 07:38:27 PM ***** Eval results *****
03/27 07:38:27 PM   att_loss = 7.5706812580626215
03/27 07:38:27 PM   cls_loss = 0.0
03/27 07:38:28 PM   global_step = 199
03/27 07:38:28 PM   loss = 8.665091428325404
03/27 07:38:28 PM   rep_loss = 1.0944102029105527






Iteration:  93%|#########2| 248/268 [00:53<00:04,  4.84it/s]
03/27 07:38:38 PM ***** Running evaluation *****
03/27 07:38:38 PM   Epoch = 0 iter 249 step
03/27 07:38:38 PM   Num examples = 1043
03/27 07:38:38 PM   Batch size = 32
03/27 07:38:38 PM ***** Eval results *****
03/27 07:38:38 PM   att_loss = 7.428348841916127
03/27 07:38:38 PM   cls_loss = 0.0
03/27 07:38:38 PM   global_step = 249
03/27 07:38:38 PM   loss = 8.463673796519696
03/27 07:38:38 PM   rep_loss = 1.0353249778230507


Epoch:   3%|▎         | 1/30 [00:57<27:55, 57.78s/it]83it/s]


Iteration:  10%|#         | 28/268 [00:05<00:49,  4.84it/s]
03/27 07:38:50 PM ***** Running evaluation *****
03/27 07:38:50 PM   Epoch = 1 iter 299 step
03/27 07:38:50 PM   Num examples = 1043
03/27 07:38:50 PM   Batch size = 32
03/27 07:38:50 PM ***** Eval results *****
03/27 07:38:50 PM   att_loss = 6.6860498785972595
03/27 07:38:50 PM   cls_loss = 0.0
03/27 07:38:50 PM   global_step = 299
03/27 07:38:50 PM   loss = 7.455416560173035
03/27 07:38:50 PM   rep_loss = 0.7693666610866785






Iteration:  30%|###       | 81/268 [00:17<00:38,  4.82it/s]
03/27 07:39:01 PM ***** Running evaluation *****
03/27 07:39:01 PM   Epoch = 1 iter 349 step
03/27 07:39:01 PM   Num examples = 1043
03/27 07:39:01 PM   Batch size = 32
03/27 07:39:01 PM ***** Eval results *****
03/27 07:39:01 PM   att_loss = 6.705311275110012
03/27 07:39:01 PM   cls_loss = 0.0
03/27 07:39:01 PM   global_step = 349
03/27 07:39:01 PM   loss = 7.467519044876099
03/27 07:39:01 PM   rep_loss = 0.7622077595896837





Iteration:  47%|####7     | 127/268 [00:27<00:29,  4.82it/s]
03/27 07:39:12 PM ***** Running evaluation *****
03/27 07:39:12 PM   Epoch = 1 iter 399 step
03/27 07:39:12 PM   Num examples = 1043
03/27 07:39:12 PM   Batch size = 32
03/27 07:39:12 PM ***** Eval results *****
03/27 07:39:12 PM   att_loss = 6.690488157850323
03/27 07:39:12 PM   cls_loss = 0.0
03/27 07:39:12 PM   global_step = 399
03/27 07:39:12 PM   loss = 7.44483397584973
03/27 07:39:12 PM   rep_loss = 0.7543458130323526






Iteration:  68%|######7   | 181/268 [00:39<00:18,  4.82it/s]
03/27 07:39:23 PM ***** Running evaluation *****
03/27 07:39:23 PM   Epoch = 1 iter 449 step
03/27 07:39:23 PM   Num examples = 1043
03/27 07:39:23 PM   Batch size = 32
03/27 07:39:23 PM ***** Eval results *****
03/27 07:39:23 PM   att_loss = 6.692408763445341
03/27 07:39:23 PM   cls_loss = 0.0
03/27 07:39:23 PM   global_step = 449
03/27 07:39:23 PM   loss = 7.441947300355513
03/27 07:39:23 PM   rep_loss = 0.7495385326526978





Iteration:  85%|########4 | 227/268 [00:49<00:08,  4.80it/s]
03/27 07:39:34 PM ***** Running evaluation *****
03/27 07:39:34 PM   Epoch = 1 iter 499 step
03/27 07:39:34 PM   Num examples = 1043
03/27 07:39:34 PM   Batch size = 32
03/27 07:39:34 PM ***** Eval results *****
03/27 07:39:34 PM   att_loss = 6.658115793918741
03/27 07:39:34 PM   cls_loss = 0.0
03/27 07:39:34 PM   global_step = 499
03/27 07:39:34 PM   loss = 7.4018213399525346
03/27 07:39:34 PM   rep_loss = 0.7437055424369615




Epoch:   7%|▋         | 2/30 [01:56<27:16, 58.43s/it]80it/s]

Iteration:   5%|5         | 14/268 [00:02<00:52,  4.80it/s]
03/27 07:39:45 PM ***** Running evaluation *****
03/27 07:39:45 PM   Epoch = 2 iter 549 step
03/27 07:39:45 PM   Num examples = 1043
03/27 07:39:45 PM   Batch size = 32
03/27 07:39:45 PM ***** Eval results *****
03/27 07:39:45 PM   att_loss = 6.230175908406576
03/27 07:39:45 PM   cls_loss = 0.0
03/27 07:39:45 PM   global_step = 549
03/27 07:39:45 PM   loss = 6.924770800272624
03/27 07:39:45 PM   rep_loss = 0.6945948600769043






Iteration:  24%|##4       | 65/268 [00:14<01:23,  2.42it/s]
03/27 07:39:56 PM ***** Running evaluation *****
03/27 07:39:56 PM   Epoch = 2 iter 599 step
03/27 07:39:56 PM   Num examples = 1043
03/27 07:39:56 PM   Batch size = 32
03/27 07:39:56 PM ***** Eval results *****
03/27 07:39:56 PM   att_loss = 6.44184836607713
03/27 07:39:56 PM   cls_loss = 0.0
03/27 07:39:56 PM   global_step = 599
03/27 07:39:56 PM   loss = 7.146965606396015
03/27 07:39:56 PM   rep_loss = 0.705117234816918





Iteration:  43%|####2     | 114/268 [00:25<00:31,  4.82it/s]
03/27 07:40:07 PM ***** Running evaluation *****
03/27 07:40:07 PM   Epoch = 2 iter 649 step
03/27 07:40:07 PM   Num examples = 1043
03/27 07:40:07 PM   Batch size = 32
03/27 07:40:07 PM ***** Eval results *****
03/27 07:40:07 PM   att_loss = 6.407271472267483
03/27 07:40:07 PM   cls_loss = 0.0
03/27 07:40:07 PM   global_step = 649
03/27 07:40:07 PM   loss = 7.107782824143119
03/27 07:40:07 PM   rep_loss = 0.7005113518756368






Iteration:  62%|######1   | 165/268 [00:36<00:42,  2.44it/s]
03/27 07:40:18 PM ***** Running evaluation *****
03/27 07:40:18 PM   Epoch = 2 iter 699 step
03/27 07:40:18 PM   Num examples = 1043
03/27 07:40:18 PM   Batch size = 32
03/27 07:40:18 PM ***** Eval results *****
03/27 07:40:18 PM   att_loss = 6.4261864257581305
03/27 07:40:18 PM   cls_loss = 0.0
03/27 07:40:18 PM   global_step = 699
03/27 07:40:18 PM   loss = 7.125455208980676
03/27 07:40:18 PM   rep_loss = 0.6992687965884353





Iteration:  80%|#######9  | 214/268 [00:47<00:11,  4.81it/s]
03/27 07:40:29 PM ***** Running evaluation *****
03/27 07:40:29 PM   Epoch = 2 iter 749 step
03/27 07:40:29 PM   Num examples = 1043
03/27 07:40:29 PM   Batch size = 32
03/27 07:40:29 PM ***** Eval results *****
03/27 07:40:29 PM   att_loss = 6.436908959233484
03/27 07:40:29 PM   cls_loss = 0.0
03/27 07:40:29 PM   global_step = 749
03/27 07:40:29 PM   loss = 7.134369317875352
03/27 07:40:29 PM   rep_loss = 0.6974603542061739






Iteration:  99%|#########8| 265/268 [00:59<00:01,  2.45it/s]
03/27 07:40:40 PM ***** Running evaluation *****
03/27 07:40:40 PM   Epoch = 2 iter 799 step
03/27 07:40:40 PM   Num examples = 1043
03/27 07:40:40 PM   Batch size = 32
03/27 07:40:40 PM ***** Eval results *****
03/27 07:40:40 PM   att_loss = 6.426877507623637
03/27 07:40:40 PM   cls_loss = 0.0
03/27 07:40:40 PM   global_step = 799
03/27 07:40:40 PM   loss = 7.122077079988875
03/27 07:40:40 PM   rep_loss = 0.6951995665172361
Epoch:  10%|█         | 3/30 [02:56<26:30, 58.90s/it]28it/s]




Iteration:  18%|#7        | 47/268 [00:09<00:45,  4.85it/s]
03/27 07:40:51 PM ***** Running evaluation *****
03/27 07:40:51 PM   Epoch = 3 iter 849 step
03/27 07:40:51 PM   Num examples = 1043
03/27 07:40:51 PM   Batch size = 32
03/27 07:40:51 PM ***** Eval results *****
03/27 07:40:51 PM   att_loss = 6.213072796662648
03/27 07:40:51 PM   cls_loss = 0.0
03/27 07:40:51 PM   global_step = 849
03/27 07:40:51 PM   loss = 6.885791877905528
03/27 07:40:51 PM   rep_loss = 0.6727190787593523






Iteration:  37%|###6      | 98/268 [00:21<01:10,  2.42it/s]
03/27 07:41:02 PM ***** Running evaluation *****
03/27 07:41:02 PM   Epoch = 3 iter 899 step
03/27 07:41:02 PM   Num examples = 1043
03/27 07:41:02 PM   Batch size = 32
03/27 07:41:02 PM ***** Eval results *****
03/27 07:41:02 PM   att_loss = 6.2570765456374815
03/27 07:41:02 PM   cls_loss = 0.0
03/27 07:41:02 PM   global_step = 899
03/27 07:41:02 PM   loss = 6.929862825237975
03/27 07:41:02 PM   rep_loss = 0.6727862716937552





Iteration:  55%|#####4    | 147/268 [00:31<00:24,  4.85it/s]
03/27 07:41:13 PM ***** Running evaluation *****
03/27 07:41:13 PM   Epoch = 3 iter 949 step
03/27 07:41:13 PM   Num examples = 1043
03/27 07:41:13 PM   Batch size = 32
03/27 07:41:13 PM ***** Eval results *****
03/27 07:41:13 PM   att_loss = 6.2871273594933585
03/27 07:41:13 PM   cls_loss = 0.0
03/27 07:41:13 PM   global_step = 949
03/27 07:41:13 PM   loss = 6.960579392072317
03/27 07:41:13 PM   rep_loss = 0.6734520217051377






Iteration:  74%|#######3  | 198/268 [00:43<00:28,  2.48it/s]
03/27 07:41:24 PM ***** Running evaluation *****
03/27 07:41:24 PM   Epoch = 3 iter 999 step
03/27 07:41:24 PM   Num examples = 1043
03/27 07:41:24 PM   Batch size = 32
03/27 07:41:24 PM ***** Eval results *****
03/27 07:41:24 PM   att_loss = 6.270541217592028
03/27 07:41:24 PM   cls_loss = 0.0
03/27 07:41:24 PM   global_step = 999
03/27 07:41:24 PM   loss = 6.9417381623778684
03/27 07:41:24 PM   rep_loss = 0.671196936958968





Iteration:  92%|#########2| 247/268 [00:53<00:04,  4.86it/s]
03/27 07:41:35 PM ***** Running evaluation *****
03/27 07:41:35 PM   Epoch = 3 iter 1049 step
03/27 07:41:35 PM   Num examples = 1043
03/27 07:41:35 PM   Batch size = 32
03/27 07:41:35 PM ***** Eval results *****
03/27 07:41:35 PM   att_loss = 6.269511570853572
03/27 07:41:35 PM   cls_loss = 0.0
03/27 07:41:35 PM   global_step = 1049
03/27 07:41:35 PM   loss = 6.939530870606823
03/27 07:41:35 PM   rep_loss = 0.670019286053796


Epoch:  13%|█▎        | 4/30 [03:54<25:27, 58.74s/it]83it/s]



Iteration:  12%|#1        | 32/268 [00:07<01:22,  2.86it/s]
03/27 07:41:46 PM ***** Running evaluation *****
03/27 07:41:46 PM   Epoch = 4 iter 1099 step
03/27 07:41:46 PM   Num examples = 1043
03/27 07:41:46 PM   Batch size = 32
03/27 07:41:46 PM ***** Eval results *****
03/27 07:41:46 PM   att_loss = 6.286262881371282
03/27 07:41:46 PM   cls_loss = 0.0
03/27 07:41:46 PM   global_step = 1099
03/27 07:41:46 PM   loss = 6.94977532663653
03/27 07:41:46 PM   rep_loss = 0.6635124568016298





Iteration:  30%|##9       | 80/268 [00:17<00:38,  4.84it/s]
03/27 07:41:57 PM ***** Running evaluation *****
03/27 07:41:57 PM   Epoch = 4 iter 1149 step
03/27 07:41:57 PM   Num examples = 1043
03/27 07:41:57 PM   Batch size = 32
03/27 07:41:57 PM ***** Eval results *****
03/27 07:41:57 PM   att_loss = 6.256325874799564
03/27 07:41:57 PM   cls_loss = 0.0
03/27 07:41:57 PM   global_step = 1149
03/27 07:41:57 PM   loss = 6.917607148488362
03/27 07:41:57 PM   rep_loss = 0.6612812641226216






Iteration:  49%|####9     | 132/268 [00:29<00:48,  2.82it/s]
03/27 07:42:08 PM ***** Running evaluation *****
03/27 07:42:08 PM   Epoch = 4 iter 1199 step
03/27 07:42:08 PM   Num examples = 1043
03/27 07:42:08 PM   Batch size = 32
03/27 07:42:08 PM ***** Eval results *****
03/27 07:42:08 PM   att_loss = 6.209990708882572
03/27 07:42:08 PM   cls_loss = 0.0
03/27 07:42:08 PM   global_step = 1199
03/27 07:42:08 PM   loss = 6.8683390580970825
03/27 07:42:08 PM   rep_loss = 0.6583483464845264





Iteration:  67%|######7   | 180/268 [00:39<00:18,  4.84it/s]
03/27 07:42:19 PM ***** Running evaluation *****
03/27 07:42:19 PM   Epoch = 4 iter 1249 step
03/27 07:42:19 PM   Num examples = 1043
03/27 07:42:19 PM   Batch size = 32
03/27 07:42:19 PM ***** Eval results *****
03/27 07:42:19 PM   att_loss = 6.182991162189462
03/27 07:42:19 PM   cls_loss = 0.0
03/27 07:42:19 PM   global_step = 1249
03/27 07:42:19 PM   loss = 6.839209419587699
03/27 07:42:19 PM   rep_loss = 0.6562182527879326






Iteration:  87%|########6 | 232/268 [00:51<00:12,  2.83it/s]
03/27 07:42:30 PM ***** Running evaluation *****
03/27 07:42:30 PM   Epoch = 4 iter 1299 step
03/27 07:42:30 PM   Num examples = 1043
03/27 07:42:30 PM   Batch size = 32
03/27 07:42:30 PM ***** Eval results *****
03/27 07:42:30 PM   att_loss = 6.198709151445529
03/27 07:42:30 PM   cls_loss = 0.0
03/27 07:42:30 PM   global_step = 1299
03/27 07:42:30 PM   loss = 6.853745945604333
03/27 07:42:30 PM   rep_loss = 0.6550367967390911



Epoch:  17%|█▋        | 5/30 [04:53<24:27, 58.68s/it]85it/s]

Iteration:   5%|4         | 13/268 [00:02<00:52,  4.85it/s]
03/27 07:42:41 PM ***** Running evaluation *****
03/27 07:42:41 PM   Epoch = 5 iter 1349 step
03/27 07:42:41 PM   Num examples = 1043
03/27 07:42:41 PM   Batch size = 32
03/27 07:42:41 PM ***** Eval results *****
03/27 07:42:41 PM   att_loss = 6.112003667013986
03/27 07:42:41 PM   cls_loss = 0.0
03/27 07:42:41 PM   global_step = 1349
03/27 07:42:41 PM   loss = 6.7563982009887695
03/27 07:42:41 PM   rep_loss = 0.6443944871425629






Iteration:  24%|##4       | 65/268 [00:14<01:11,  2.84it/s]
03/27 07:42:52 PM ***** Running evaluation *****
03/27 07:42:52 PM   Epoch = 5 iter 1399 step
03/27 07:42:52 PM   Num examples = 1043
03/27 07:42:52 PM   Batch size = 32
03/27 07:42:52 PM ***** Eval results *****
03/27 07:42:52 PM   att_loss = 6.137298621237278
03/27 07:42:52 PM   cls_loss = 0.0
03/27 07:42:52 PM   global_step = 1399
03/27 07:42:52 PM   loss = 6.784199006855488
03/27 07:42:52 PM   rep_loss = 0.646900394000113





Iteration:  42%|####2     | 113/268 [00:24<00:32,  4.84it/s]
03/27 07:43:03 PM ***** Running evaluation *****
03/27 07:43:03 PM   Epoch = 5 iter 1449 step
03/27 07:43:03 PM   Num examples = 1043
03/27 07:43:03 PM   Batch size = 32
03/27 07:43:03 PM ***** Eval results *****
03/27 07:43:03 PM   att_loss = 6.090391828302751
03/27 07:43:03 PM   cls_loss = 0.0
03/27 07:43:03 PM   global_step = 1449
03/27 07:43:03 PM   loss = 6.734807675344902
03/27 07:43:03 PM   rep_loss = 0.6444158548848671






Iteration:  62%|######1   | 165/268 [00:36<00:35,  2.90it/s]
03/27 07:43:14 PM ***** Running evaluation *****
03/27 07:43:14 PM   Epoch = 5 iter 1499 step
03/27 07:43:14 PM   Num examples = 1043
03/27 07:43:14 PM   Batch size = 32
03/27 07:43:14 PM ***** Eval results *****
03/27 07:43:14 PM   att_loss = 6.102632449894417
03/27 07:43:14 PM   cls_loss = 0.0
03/27 07:43:14 PM   global_step = 1499
03/27 07:43:14 PM   loss = 6.7456624740507545
03/27 07:43:14 PM   rep_loss = 0.6430300270638815





Iteration:  79%|#######9  | 213/268 [00:46<00:11,  4.84it/s]
03/27 07:43:25 PM ***** Running evaluation *****
03/27 07:43:25 PM   Epoch = 5 iter 1549 step
03/27 07:43:25 PM   Num examples = 1043
03/27 07:43:25 PM   Batch size = 32
03/27 07:43:25 PM ***** Eval results *****
03/27 07:43:25 PM   att_loss = 6.100154865567929
03/27 07:43:25 PM   cls_loss = 0.0
03/27 07:43:25 PM   global_step = 1549
03/27 07:43:25 PM   loss = 6.741990376855726
03/27 07:43:25 PM   rep_loss = 0.6418355073884269






Iteration:  99%|#########8| 265/268 [00:58<00:01,  2.86it/s]
03/27 07:43:36 PM ***** Running evaluation *****
03/27 07:43:36 PM   Epoch = 5 iter 1599 step
03/27 07:43:36 PM   Num examples = 1043
03/27 07:43:36 PM   Batch size = 32
03/27 07:43:36 PM ***** Eval results *****
03/27 07:43:36 PM   att_loss = 6.100184547178673
03/27 07:43:36 PM   cls_loss = 0.0
03/27 07:43:36 PM   global_step = 1599
03/27 07:43:36 PM   loss = 6.741134918097294
03/27 07:43:36 PM   rep_loss = 0.6409503724990468
Epoch:  20%|██        | 6/30 [05:52<23:32, 58.85s/it]62it/s]




Iteration:  17%|#7        | 46/268 [00:09<00:45,  4.84it/s]
03/27 07:43:47 PM ***** Running evaluation *****
03/27 07:43:47 PM   Epoch = 6 iter 1649 step
03/27 07:43:47 PM   Num examples = 1043
03/27 07:43:47 PM   Batch size = 32
03/27 07:43:47 PM ***** Eval results *****
03/27 07:43:47 PM   att_loss = 6.022228636640183
03/27 07:43:47 PM   cls_loss = 0.0
03/27 07:43:47 PM   global_step = 1649
03/27 07:43:47 PM   loss = 6.653832597935454
03/27 07:43:47 PM   rep_loss = 0.6316039638316377






Iteration:  37%|###6      | 98/268 [00:21<00:59,  2.84it/s]
03/27 07:43:58 PM ***** Running evaluation *****
03/27 07:43:58 PM   Epoch = 6 iter 1699 step
03/27 07:43:58 PM   Num examples = 1043
03/27 07:43:58 PM   Batch size = 32
03/27 07:43:58 PM ***** Eval results *****
03/27 07:43:58 PM   att_loss = 6.054369597090888
03/27 07:43:58 PM   cls_loss = 0.0
03/27 07:43:58 PM   global_step = 1699
03/27 07:43:58 PM   loss = 6.686873834157727
03/27 07:43:58 PM   rep_loss = 0.63250422354826





Iteration:  54%|#####4    | 146/268 [00:31<00:25,  4.84it/s]
03/27 07:44:09 PM ***** Running evaluation *****
03/27 07:44:09 PM   Epoch = 6 iter 1749 step
03/27 07:44:09 PM   Num examples = 1043
03/27 07:44:09 PM   Batch size = 32
03/27 07:44:09 PM ***** Eval results *****
03/27 07:44:09 PM   att_loss = 6.047359236243631
03/27 07:44:09 PM   cls_loss = 0.0
03/27 07:44:09 PM   global_step = 1749
03/27 07:44:09 PM   loss = 6.679043221635883
03/27 07:44:09 PM   rep_loss = 0.6316839756608821






Iteration:  74%|#######4  | 199/268 [00:43<00:20,  3.32it/s]
03/27 07:44:20 PM ***** Running evaluation *****
03/27 07:44:20 PM   Epoch = 6 iter 1799 step
03/27 07:44:20 PM   Num examples = 1043
03/27 07:44:20 PM   Batch size = 32
03/27 07:44:20 PM ***** Eval results *****
03/27 07:44:20 PM   att_loss = 6.039677160040376
03/27 07:44:20 PM   cls_loss = 0.0
03/27 07:44:20 PM   global_step = 1799
03/27 07:44:20 PM   loss = 6.670705475782985
03/27 07:44:20 PM   rep_loss = 0.6310283081785677





Iteration:  92%|#########1| 246/268 [00:53<00:04,  4.84it/s]
03/27 07:44:31 PM ***** Running evaluation *****
03/27 07:44:31 PM   Epoch = 6 iter 1849 step
03/27 07:44:31 PM   Num examples = 1043
03/27 07:44:31 PM   Batch size = 32
03/27 07:44:31 PM ***** Eval results *****
03/27 07:44:31 PM   att_loss = 6.038799368900809
03/27 07:44:31 PM   cls_loss = 0.0
03/27 07:44:31 PM   global_step = 1849
03/27 07:44:31 PM   loss = 6.668669080927304
03/27 07:44:31 PM   rep_loss = 0.6298697052696939


Epoch:  23%|██▎       | 7/30 [06:50<22:31, 58.75s/it]84it/s]



Iteration:  12%|#1        | 32/268 [00:07<01:12,  3.26it/s]
03/27 07:44:42 PM ***** Running evaluation *****
03/27 07:44:42 PM   Epoch = 7 iter 1899 step
03/27 07:44:42 PM   Num examples = 1043
03/27 07:44:42 PM   Batch size = 32
03/27 07:44:42 PM ***** Eval results *****
03/27 07:44:42 PM   att_loss = 5.900824721654256
03/27 07:44:42 PM   cls_loss = 0.0
03/27 07:44:42 PM   global_step = 1899
03/27 07:44:42 PM   loss = 6.520616801579793
03/27 07:44:42 PM   rep_loss = 0.6197920620441437





Iteration:  29%|##9       | 79/268 [00:16<00:39,  4.84it/s]
03/27 07:44:53 PM ***** Running evaluation *****
03/27 07:44:53 PM   Epoch = 7 iter 1949 step
03/27 07:44:53 PM   Num examples = 1043
03/27 07:44:53 PM   Batch size = 32
03/27 07:44:53 PM ***** Eval results *****
03/27 07:44:53 PM   att_loss = 5.94019301533699
03/27 07:44:53 PM   cls_loss = 0.0
03/27 07:44:53 PM   global_step = 1949
03/27 07:44:53 PM   loss = 6.561323249340058
03/27 07:44:53 PM   rep_loss = 0.6211302079260349





Iteration:  47%|####7     | 126/268 [00:27<00:29,  4.85it/s]
03/27 07:45:04 PM ***** Running evaluation *****
03/27 07:45:04 PM   Epoch = 7 iter 1999 step
03/27 07:45:04 PM   Num examples = 1043
03/27 07:45:04 PM   Batch size = 32
03/27 07:45:04 PM ***** Eval results *****
03/27 07:45:04 PM   att_loss = 5.954231306222769
03/27 07:45:04 PM   cls_loss = 0.0
03/27 07:45:04 PM   global_step = 1999
03/27 07:45:04 PM   loss = 6.575478146626399

Iteration:  49%|####9     | 132/268 [00:29<00:41,  3.29it/s]





Iteration:  67%|######6   | 179/268 [00:38<00:18,  4.85it/s]
03/27 07:45:15 PM ***** Running evaluation *****
03/27 07:45:15 PM   Epoch = 7 iter 2049 step
03/27 07:45:15 PM   Num examples = 1043
03/27 07:45:15 PM   Batch size = 32
03/27 07:45:15 PM ***** Eval results *****
03/27 07:45:15 PM   att_loss = 5.957748903168572
03/27 07:45:15 PM   cls_loss = 0.0
03/27 07:45:15 PM   global_step = 2049
03/27 07:45:15 PM   loss = 6.579027522934807
03/27 07:45:15 PM   rep_loss = 0.6212786035405264





Iteration:  84%|########4 | 226/268 [00:49<00:08,  4.84it/s]
03/27 07:45:26 PM ***** Running evaluation *****
03/27 07:45:26 PM   Epoch = 7 iter 2099 step
03/27 07:45:26 PM   Num examples = 1043
03/27 07:45:26 PM   Batch size = 32
03/27 07:45:26 PM ***** Eval results *****
03/27 07:45:26 PM   att_loss = 5.965004406804624
03/27 07:45:26 PM   cls_loss = 0.0
03/27 07:45:26 PM   global_step = 2099
03/27 07:45:26 PM   loss = 6.586384700692219
03/27 07:45:26 PM   rep_loss = 0.6213802736738454




Epoch:  27%|██▋       | 8/30 [07:49<21:30, 58.67s/it]84it/s]

Iteration:   4%|4         | 12/268 [00:02<00:52,  4.84it/s]
03/27 07:45:37 PM ***** Running evaluation *****
03/27 07:45:37 PM   Epoch = 8 iter 2149 step
03/27 07:45:37 PM   Num examples = 1043
03/27 07:45:37 PM   Batch size = 32
03/27 07:45:37 PM ***** Eval results *****
03/27 07:45:37 PM   att_loss = 5.95800231053279
03/27 07:45:37 PM   cls_loss = 0.0
03/27 07:45:37 PM   global_step = 2149
03/27 07:45:37 PM   loss = 6.57858760540302
03/27 07:45:37 PM   rep_loss = 0.6205853132101206





Iteration:  22%|##2       | 59/268 [00:12<00:43,  4.84it/s]
03/27 07:45:48 PM ***** Running evaluation *****
03/27 07:45:48 PM   Epoch = 8 iter 2199 step
03/27 07:45:48 PM   Num examples = 1043
03/27 07:45:48 PM   Batch size = 32
03/27 07:45:48 PM ***** Eval results *****
03/27 07:45:48 PM   att_loss = 5.94639759971982
03/27 07:45:48 PM   cls_loss = 0.0
03/27 07:45:48 PM   global_step = 2199
03/27 07:45:48 PM   loss = 6.563339331793407
03/27 07:45:48 PM   rep_loss = 0.616941701798212






Iteration:  42%|####1     | 112/268 [00:24<00:32,  4.84it/s]
03/27 07:45:59 PM ***** Running evaluation *****
03/27 07:45:59 PM   Epoch = 8 iter 2249 step
03/27 07:45:59 PM   Num examples = 1043
03/27 07:45:59 PM   Batch size = 32
03/27 07:45:59 PM ***** Eval results *****
03/27 07:45:59 PM   att_loss = 5.940592449323266
03/27 07:45:59 PM   cls_loss = 0.0
03/27 07:45:59 PM   global_step = 2249
03/27 07:45:59 PM   loss = 6.557279050877664
03/27 07:45:59 PM   rep_loss = 0.6166865841477318





Iteration:  59%|#####9    | 159/268 [00:34<00:22,  4.84it/s]
03/27 07:46:10 PM ***** Running evaluation *****
03/27 07:46:10 PM   Epoch = 8 iter 2299 step
03/27 07:46:10 PM   Num examples = 1043
03/27 07:46:10 PM   Batch size = 32
03/27 07:46:10 PM ***** Eval results *****
03/27 07:46:10 PM   att_loss = 5.917975297003436
03/27 07:46:10 PM   cls_loss = 0.0
03/27 07:46:10 PM   global_step = 2299
03/27 07:46:10 PM   loss = 6.533648452875805
03/27 07:46:10 PM   rep_loss = 0.6156731445365157






Iteration:  79%|#######9  | 212/268 [00:46<00:11,  4.84it/s]
03/27 07:46:21 PM ***** Running evaluation *****
03/27 07:46:21 PM   Epoch = 8 iter 2349 step
03/27 07:46:21 PM   Num examples = 1043
03/27 07:46:21 PM   Batch size = 32
03/27 07:46:21 PM ***** Eval results *****
03/27 07:46:21 PM   att_loss = 5.916263535548824
03/27 07:46:21 PM   cls_loss = 0.0
03/27 07:46:21 PM   global_step = 2349
03/27 07:46:21 PM   loss = 6.530879376639782
03/27 07:46:21 PM   rep_loss = 0.6146158329757726





Iteration:  97%|#########6| 259/268 [00:56<00:01,  4.85it/s]
03/27 07:46:32 PM ***** Running evaluation *****
03/27 07:46:32 PM   Epoch = 8 iter 2399 step
03/27 07:46:32 PM   Num examples = 1043
03/27 07:46:32 PM   Batch size = 32
03/27 07:46:32 PM ***** Eval results *****
03/27 07:46:32 PM   att_loss = 5.930026815871322
03/27 07:46:32 PM   cls_loss = 0.0
03/27 07:46:32 PM   global_step = 2399
03/27 07:46:32 PM   loss = 6.544466444747983
03/27 07:46:32 PM   rep_loss = 0.6144396193580483

Epoch:  30%|███       | 9/30 [08:48<20:35, 58.85s/it]88it/s]




Iteration:  17%|#6        | 45/268 [00:09<00:45,  4.86it/s]
03/27 07:46:43 PM ***** Running evaluation *****
03/27 07:46:43 PM   Epoch = 9 iter 2449 step
03/27 07:46:43 PM   Num examples = 1043
03/27 07:46:43 PM   Batch size = 32
03/27 07:46:43 PM ***** Eval results *****
03/27 07:46:43 PM   att_loss = 5.896143882170968
03/27 07:46:43 PM   cls_loss = 0.0
03/27 07:46:43 PM   global_step = 2449
03/27 07:46:43 PM   loss = 6.506722025249315
03/27 07:46:43 PM   rep_loss = 0.6105781495571136





Iteration:  34%|###4      | 92/268 [00:19<00:36,  4.84it/s]
03/27 07:46:54 PM ***** Running evaluation *****
03/27 07:46:54 PM   Epoch = 9 iter 2499 step
03/27 07:46:54 PM   Num examples = 1043
03/27 07:46:54 PM   Batch size = 32
03/27 07:46:54 PM ***** Eval results *****
03/27 07:46:54 PM   att_loss = 5.911739140748978
03/27 07:46:54 PM   cls_loss = 0.0
03/27 07:46:54 PM   global_step = 2499
03/27 07:46:54 PM   loss = 6.521648804346721
03/27 07:46:54 PM   rep_loss = 0.6099096518009901






Iteration:  54%|#####4    | 145/268 [00:31<00:25,  4.85it/s]
03/27 07:47:05 PM ***** Running evaluation *****
03/27 07:47:05 PM   Epoch = 9 iter 2549 step
03/27 07:47:05 PM   Num examples = 1043
03/27 07:47:05 PM   Batch size = 32
03/27 07:47:05 PM ***** Eval results *****
03/27 07:47:05 PM   att_loss = 5.906173170429387
03/27 07:47:05 PM   cls_loss = 0.0
03/27 07:47:05 PM   global_step = 2549
03/27 07:47:05 PM   loss = 6.5155834727091335
03/27 07:47:05 PM   rep_loss = 0.6094102835002011





Iteration:  72%|#######1  | 192/268 [00:41<00:15,  4.86it/s]
03/27 07:47:16 PM ***** Running evaluation *****
03/27 07:47:16 PM   Epoch = 9 iter 2599 step
03/27 07:47:16 PM   Num examples = 1043
03/27 07:47:16 PM   Batch size = 32
03/27 07:47:16 PM ***** Eval results *****
03/27 07:47:16 PM   att_loss = 5.917038499092569
03/27 07:47:16 PM   cls_loss = 0.0
03/27 07:47:16 PM   global_step = 2599
03/27 07:47:16 PM   loss = 6.526230379026764
03/27 07:47:16 PM   rep_loss = 0.6091918610796636






Iteration:  91%|#########1| 245/268 [00:53<00:04,  4.83it/s]
03/27 07:47:27 PM ***** Running evaluation *****
03/27 07:47:27 PM   Epoch = 9 iter 2649 step
03/27 07:47:27 PM   Num examples = 1043
03/27 07:47:27 PM   Batch size = 32
03/27 07:47:27 PM ***** Eval results *****
03/27 07:47:27 PM   att_loss = 5.908881408412282
03/27 07:47:27 PM   cls_loss = 0.0
03/27 07:47:27 PM   global_step = 2649
03/27 07:47:27 PM   loss = 6.517295480743656
03/27 07:47:27 PM   rep_loss = 0.6084140541592264


Epoch:  33%|███▎      | 10/30 [09:47<19:35, 58.78s/it]4it/s]


Iteration:   9%|9         | 25/268 [00:05<00:50,  4.84it/s]
03/27 07:47:38 PM ***** Running evaluation *****
03/27 07:47:38 PM   Epoch = 10 iter 2699 step
03/27 07:47:38 PM   Num examples = 1043
03/27 07:47:38 PM   Batch size = 32
03/27 07:47:38 PM ***** Eval results *****
03/27 07:47:38 PM   att_loss = 5.932870716884218
03/27 07:47:38 PM   cls_loss = 0.0
03/27 07:47:38 PM   global_step = 2699
03/27 07:47:38 PM   loss = 6.54051686977518

Iteration:  12%|#1        | 32/268 [00:07<01:05,  3.62it/s]





Iteration:  29%|##9       | 78/268 [00:16<00:39,  4.83it/s]
03/27 07:47:49 PM ***** Running evaluation *****
03/27 07:47:49 PM   Epoch = 10 iter 2749 step
03/27 07:47:49 PM   Num examples = 1043
03/27 07:47:49 PM   Batch size = 32
03/27 07:47:49 PM ***** Eval results *****
03/27 07:47:49 PM   att_loss = 5.897302398198767
03/27 07:47:49 PM   cls_loss = 0.0
03/27 07:47:49 PM   global_step = 2749
03/27 07:47:49 PM   loss = 6.503901590274859
03/27 07:47:49 PM   rep_loss = 0.6065992124472992





Iteration:  46%|####5     | 123/268 [00:26<00:29,  4.84it/s]
03/27 07:48:00 PM ***** Running evaluation *****
03/27 07:48:00 PM   Epoch = 10 iter 2799 step
03/27 07:48:00 PM   Num examples = 1043
03/27 07:48:00 PM   Batch size = 32
03/27 07:48:00 PM ***** Eval results *****
03/27 07:48:00 PM   att_loss = 5.84992084577102
03/27 07:48:00 PM   cls_loss = 0.0
03/27 07:48:00 PM   global_step = 2799
03/27 07:48:00 PM   loss = 6.455110309659973
03/27 07:48:00 PM   rep_loss = 0.6051894703576731






Iteration:  66%|######6   | 178/268 [00:38<00:18,  4.84it/s]
03/27 07:48:11 PM ***** Running evaluation *****
03/27 07:48:11 PM   Epoch = 10 iter 2849 step
03/27 07:48:11 PM   Num examples = 1043
03/27 07:48:11 PM   Batch size = 32
03/27 07:48:11 PM ***** Eval results *****
03/27 07:48:11 PM   att_loss = 5.873082107671812
03/27 07:48:11 PM   cls_loss = 0.0
03/27 07:48:11 PM   global_step = 2849
03/27 07:48:11 PM   loss = 6.4777805365663665
03/27 07:48:11 PM   rep_loss = 0.6046984245657255





Iteration:  83%|########3 | 223/268 [00:48<00:09,  4.85it/s]
03/27 07:48:22 PM ***** Running evaluation *****
03/27 07:48:22 PM   Epoch = 10 iter 2899 step
03/27 07:48:22 PM   Num examples = 1043
03/27 07:48:22 PM   Batch size = 32
03/27 07:48:22 PM ***** Eval results *****
03/27 07:48:22 PM   att_loss = 5.8665073677962525
03/27 07:48:22 PM   cls_loss = 0.0
03/27 07:48:22 PM   global_step = 2899
03/27 07:48:22 PM   loss = 6.47025100008369
03/27 07:48:22 PM   rep_loss = 0.6037436236981221




Epoch:  37%|███▋      | 11/30 [10:45<18:35, 58.70s/it]4it/s]

Iteration:   4%|4         | 11/268 [00:02<00:53,  4.84it/s]
03/27 07:48:33 PM ***** Running evaluation *****
03/27 07:48:33 PM   Epoch = 11 iter 2949 step
03/27 07:48:33 PM   Num examples = 1043
03/27 07:48:33 PM   Batch size = 32
03/27 07:48:33 PM ***** Eval results *****
03/27 07:48:33 PM   att_loss = 5.863982041676839
03/27 07:48:33 PM   cls_loss = 0.0
03/27 07:48:33 PM   global_step = 2949
03/27 07:48:33 PM   loss = 6.465553243954976
03/27 07:48:33 PM   rep_loss = 0.6015712469816208





Iteration:  21%|##        | 56/268 [00:12<00:43,  4.84it/s]
03/27 07:48:44 PM ***** Running evaluation *****
03/27 07:48:44 PM   Epoch = 11 iter 2999 step
03/27 07:48:44 PM   Num examples = 1043
03/27 07:48:44 PM   Batch size = 32
03/27 07:48:44 PM ***** Eval results *****
03/27 07:48:44 PM   att_loss = 5.808488668933991
03/27 07:48:44 PM   cls_loss = 0.0
03/27 07:48:44 PM   global_step = 2999
03/27 07:48:44 PM   loss = 6.406169837520968
03/27 07:48:44 PM   rep_loss = 0.5976811705097076






Iteration:  41%|####1     | 111/268 [00:24<00:32,  4.85it/s]
03/27 07:48:55 PM ***** Running evaluation *****
03/27 07:48:55 PM   Epoch = 11 iter 3049 step
03/27 07:48:55 PM   Num examples = 1043
03/27 07:48:55 PM   Batch size = 32
03/27 07:48:55 PM ***** Eval results *****
03/27 07:48:55 PM   att_loss = 5.826798498630524
03/27 07:48:55 PM   cls_loss = 0.0
03/27 07:48:55 PM   global_step = 3049
03/27 07:48:55 PM   loss = 6.425322847706931
03/27 07:48:55 PM   rep_loss = 0.5985243320465088





Iteration:  59%|#####8    | 157/268 [00:34<00:22,  4.84it/s]
03/27 07:49:06 PM ***** Running evaluation *****
03/27 07:49:06 PM   Epoch = 11 iter 3099 step
03/27 07:49:06 PM   Num examples = 1043
03/27 07:49:06 PM   Batch size = 32
03/27 07:49:06 PM ***** Eval results *****
03/27 07:49:06 PM   att_loss = 5.82454584851677
03/27 07:49:06 PM   cls_loss = 0.0
03/27 07:49:06 PM   global_step = 3099
03/27 07:49:06 PM   loss = 6.42298725799278
03/27 07:49:06 PM   rep_loss = 0.5984414091080795






Iteration:  79%|#######8  | 211/268 [00:46<00:11,  4.84it/s]
03/27 07:49:17 PM ***** Running evaluation *****
03/27 07:49:17 PM   Epoch = 11 iter 3149 step
03/27 07:49:17 PM   Num examples = 1043
03/27 07:49:17 PM   Batch size = 32
03/27 07:49:17 PM ***** Eval results *****
03/27 07:49:17 PM   att_loss = 5.824498918821227
03/27 07:49:17 PM   cls_loss = 0.0
03/27 07:49:17 PM   global_step = 3149
03/27 07:49:17 PM   loss = 6.4224282075774
03/27 07:49:17 PM   rep_loss = 0.5979292910054045





Iteration:  96%|#########5| 257/268 [00:56<00:02,  4.84it/s]
03/27 07:49:28 PM ***** Running evaluation *****
03/27 07:49:28 PM   Epoch = 11 iter 3199 step
03/27 07:49:28 PM   Num examples = 1043
03/27 07:49:28 PM   Batch size = 32
03/27 07:49:28 PM ***** Eval results *****
03/27 07:49:28 PM   att_loss = 5.8334097771244195
03/27 07:49:28 PM   cls_loss = 0.0
03/27 07:49:28 PM   global_step = 3199
03/27 07:49:28 PM   loss = 6.4317394613309675
03/27 07:49:28 PM   rep_loss = 0.5983296853440409

Epoch:  40%|████      | 12/30 [11:45<17:39, 58.86s/it]2it/s]




Iteration:  16%|#6        | 44/268 [00:09<00:46,  4.84it/s]
03/27 07:49:39 PM ***** Running evaluation *****
03/27 07:49:39 PM   Epoch = 12 iter 3249 step
03/27 07:49:39 PM   Num examples = 1043
03/27 07:49:39 PM   Batch size = 32
03/27 07:49:39 PM ***** Eval results *****
03/27 07:49:39 PM   att_loss = 5.7702862103780115
03/27 07:49:39 PM   cls_loss = 0.0
03/27 07:49:39 PM   global_step = 3249
03/27 07:49:39 PM   loss = 6.363251940409342
03/27 07:49:39 PM   rep_loss = 0.5929657035403781





Iteration:  34%|###3      | 90/268 [00:19<00:36,  4.84it/s]
03/27 07:49:50 PM ***** Running evaluation *****
03/27 07:49:50 PM   Epoch = 12 iter 3299 step
03/27 07:49:50 PM   Num examples = 1043
03/27 07:49:50 PM   Batch size = 32
03/27 07:49:50 PM ***** Eval results *****
03/27 07:49:50 PM   att_loss = 5.8216830353987845
03/27 07:49:50 PM   cls_loss = 0.0
03/27 07:49:50 PM   global_step = 3299
03/27 07:49:50 PM   loss = 6.416359319184956
03/27 07:49:50 PM   rep_loss = 0.5946762706104077






Iteration:  54%|#####3    | 144/268 [00:31<00:25,  4.84it/s]
03/27 07:50:01 PM ***** Running evaluation *****
03/27 07:50:01 PM   Epoch = 12 iter 3349 step
03/27 07:50:01 PM   Num examples = 1043
03/27 07:50:01 PM   Batch size = 32
03/27 07:50:01 PM ***** Eval results *****
03/27 07:50:01 PM   att_loss = 5.815495221368198
03/27 07:50:01 PM   cls_loss = 0.0
03/27 07:50:01 PM   global_step = 3349
03/27 07:50:01 PM   loss = 6.409623708396122
03/27 07:50:01 PM   rep_loss = 0.594128483328326





Iteration:  71%|#######   | 190/268 [00:41<00:16,  4.85it/s]
03/27 07:50:12 PM ***** Running evaluation *****
03/27 07:50:12 PM   Epoch = 12 iter 3399 step
03/27 07:50:12 PM   Num examples = 1043
03/27 07:50:12 PM   Batch size = 32
03/27 07:50:12 PM ***** Eval results *****
03/27 07:50:12 PM   att_loss = 5.807319171612079
03/27 07:50:12 PM   cls_loss = 0.0
03/27 07:50:12 PM   global_step = 3399
03/27 07:50:12 PM   loss = 6.401978531861917
03/27 07:50:12 PM   rep_loss = 0.5946593559705294






Iteration:  91%|#########1| 244/268 [00:53<00:04,  4.84it/s]
03/27 07:50:23 PM ***** Running evaluation *****
03/27 07:50:23 PM   Epoch = 12 iter 3449 step
03/27 07:50:23 PM   Num examples = 1043
03/27 07:50:23 PM   Batch size = 32
03/27 07:50:23 PM ***** Eval results *****
03/27 07:50:23 PM   att_loss = 5.80505587714059
03/27 07:50:23 PM   cls_loss = 0.0
03/27 07:50:23 PM   global_step = 3449
03/27 07:50:23 PM   loss = 6.399435629163469
03/27 07:50:23 PM   rep_loss = 0.5943797512930267


Epoch:  43%|████▎     | 13/30 [12:43<16:38, 58.74s/it]6it/s]


Iteration:   9%|8         | 23/268 [00:04<00:50,  4.85it/s]
03/27 07:50:34 PM ***** Running evaluation *****
03/27 07:50:34 PM   Epoch = 13 iter 3499 step
03/27 07:50:34 PM   Num examples = 1043
03/27 07:50:34 PM   Batch size = 32
03/27 07:50:34 PM ***** Eval results *****
03/27 07:50:34 PM   att_loss = 5.851004293986729
03/27 07:50:34 PM   cls_loss = 0.0
03/27 07:50:34 PM   global_step = 3499
03/27 07:50:34 PM   loss = 6.445032613618033
03/27 07:50:34 PM   rep_loss = 0.5940283728497369






Iteration:  29%|##8       | 77/268 [00:16<00:39,  4.85it/s]
03/27 07:50:45 PM ***** Running evaluation *****
03/27 07:50:45 PM   Epoch = 13 iter 3549 step
03/27 07:50:45 PM   Num examples = 1043
03/27 07:50:45 PM   Batch size = 32
03/27 07:50:45 PM ***** Eval results *****
03/27 07:50:45 PM   att_loss = 5.792611574515318
03/27 07:50:45 PM   cls_loss = 0.0
03/27 07:50:45 PM   global_step = 3549
03/27 07:50:45 PM   loss = 6.3850836753845215
03/27 07:50:45 PM   rep_loss = 0.5924721161524454





Iteration:  46%|####6     | 124/268 [00:26<00:29,  4.84it/s]
03/27 07:50:56 PM ***** Running evaluation *****
03/27 07:50:56 PM   Epoch = 13 iter 3599 step
03/27 07:50:56 PM   Num examples = 1043
03/27 07:50:56 PM   Batch size = 32
03/27 07:50:56 PM ***** Eval results *****
03/27 07:50:56 PM   att_loss = 5.792534809559584
03/27 07:50:56 PM   cls_loss = 0.0
03/27 07:50:56 PM   global_step = 3599
03/27 07:50:56 PM   loss = 6.384562503546476
03/27 07:50:56 PM   rep_loss = 0.5920277200639248






Iteration:  66%|######6   | 177/268 [00:38<00:18,  4.84it/s]
03/27 07:51:07 PM ***** Running evaluation *****
03/27 07:51:07 PM   Epoch = 13 iter 3649 step
03/27 07:51:07 PM   Num examples = 1043
03/27 07:51:07 PM   Batch size = 32
03/27 07:51:07 PM ***** Eval results *****
03/27 07:51:07 PM   att_loss = 5.793710247854168
03/27 07:51:07 PM   cls_loss = 0.0
03/27 07:51:07 PM   global_step = 3649
03/27 07:51:07 PM   loss = 6.385387980536128
03/27 07:51:07 PM   rep_loss = 0.5916777571265617





Iteration:  84%|########3 | 224/268 [00:48<00:09,  4.85it/s]
03/27 07:51:18 PM ***** Running evaluation *****
03/27 07:51:18 PM   Epoch = 13 iter 3699 step
03/27 07:51:18 PM   Num examples = 1043
03/27 07:51:18 PM   Batch size = 32
03/27 07:51:18 PM ***** Eval results *****
03/27 07:51:18 PM   att_loss = 5.796242063505607
03/27 07:51:18 PM   cls_loss = 0.0
03/27 07:51:18 PM   global_step = 3699
03/27 07:51:18 PM   loss = 6.387839497181407
03/27 07:51:18 PM   rep_loss = 0.5915974527597427




Epoch:  47%|████▋     | 14/30 [13:42<15:38, 58.68s/it]4it/s]

Iteration:   4%|3         | 10/268 [00:02<00:53,  4.84it/s]
03/27 07:51:29 PM ***** Running evaluation *****
03/27 07:51:29 PM   Epoch = 14 iter 3749 step
03/27 07:51:29 PM   Num examples = 1043
03/27 07:51:29 PM   Batch size = 32
03/27 07:51:29 PM ***** Eval results *****
03/27 07:51:29 PM   att_loss = 5.735884969884699
03/27 07:51:29 PM   cls_loss = 0.0
03/27 07:51:29 PM   global_step = 3749
03/27 07:51:29 PM   loss = 6.320633931593462
03/27 07:51:29 PM   rep_loss = 0.5847489129413258





Iteration:  21%|##1       | 57/268 [00:12<00:43,  4.84it/s]
03/27 07:51:40 PM ***** Running evaluation *****
03/27 07:51:40 PM   Epoch = 14 iter 3799 step
03/27 07:51:40 PM   Num examples = 1043
03/27 07:51:40 PM   Batch size = 32
03/27 07:51:40 PM ***** Eval results *****
03/27 07:51:40 PM   att_loss = 5.751980570496106
03/27 07:51:40 PM   cls_loss = 0.0
03/27 07:51:40 PM   global_step = 3799
03/27 07:51:40 PM   loss = 6.339480689314545
03/27 07:51:40 PM   rep_loss = 0.5875000973216823






Iteration:  41%|####1     | 110/268 [00:24<00:32,  4.84it/s]
03/27 07:51:51 PM ***** Running evaluation *****
03/27 07:51:51 PM   Epoch = 14 iter 3849 step
03/27 07:51:51 PM   Num examples = 1043
03/27 07:51:51 PM   Batch size = 32
03/27 07:51:51 PM ***** Eval results *****
03/27 07:51:51 PM   att_loss = 5.723219313063063
03/27 07:51:51 PM   cls_loss = 0.0
03/27 07:51:51 PM   global_step = 3849
03/27 07:51:51 PM   loss = 6.309434959480354
03/27 07:51:51 PM   rep_loss = 0.5862156426584398





Iteration:  59%|#####8    | 157/268 [00:34<00:22,  4.83it/s]
03/27 07:52:03 PM ***** Running evaluation *****
03/27 07:52:03 PM   Epoch = 14 iter 3899 step
03/27 07:52:03 PM   Num examples = 1043
03/27 07:52:03 PM   Batch size = 32
03/27 07:52:03 PM ***** Eval results *****
03/27 07:52:03 PM   att_loss = 5.745992011905457
03/27 07:52:03 PM   cls_loss = 0.0
03/27 07:52:03 PM   global_step = 3899
03/27 07:52:03 PM   loss = 6.333009968633237
03/27 07:52:03 PM   rep_loss = 0.5870179489532613






Iteration:  78%|#######8  | 210/268 [00:46<00:11,  4.84it/s]
03/27 07:52:13 PM ***** Running evaluation *****
03/27 07:52:13 PM   Epoch = 14 iter 3949 step
03/27 07:52:13 PM   Num examples = 1043
03/27 07:52:13 PM   Batch size = 32
03/27 07:52:13 PM ***** Eval results *****
03/27 07:52:13 PM   att_loss = 5.767587284341243
03/27 07:52:13 PM   cls_loss = 0.0
03/27 07:52:13 PM   global_step = 3949
03/27 07:52:13 PM   loss = 6.355915397264381
03/27 07:52:13 PM   rep_loss = 0.5883281106632468





Iteration:  96%|#########5| 257/268 [00:56<00:02,  4.84it/s]
03/27 07:52:24 PM ***** Running evaluation *****
03/27 07:52:24 PM   Epoch = 14 iter 3999 step
03/27 07:52:24 PM   Num examples = 1043
03/27 07:52:24 PM   Batch size = 32
03/27 07:52:24 PM ***** Eval results *****
03/27 07:52:24 PM   att_loss = 5.764584793441597
03/27 07:52:24 PM   cls_loss = 0.0
03/27 07:52:24 PM   global_step = 3999
03/27 07:52:24 PM   loss = 6.352395180084696
03/27 07:52:24 PM   rep_loss = 0.5878103909821346

Epoch:  50%|█████     | 15/30 [14:41<14:42, 58.85s/it]6it/s]




Iteration:  16%|#6        | 43/268 [00:08<00:46,  4.84it/s]
03/27 07:52:35 PM ***** Running evaluation *****
03/27 07:52:35 PM   Epoch = 15 iter 4049 step
03/27 07:52:35 PM   Num examples = 1043
03/27 07:52:35 PM   Batch size = 32
03/27 07:52:35 PM ***** Eval results *****
03/27 07:52:35 PM   att_loss = 5.695505391467702
03/27 07:52:35 PM   cls_loss = 0.0
03/27 07:52:35 PM   global_step = 4049
03/27 07:52:35 PM   loss = 6.278609796003862
03/27 07:52:35 PM   rep_loss = 0.5831043991175565





Iteration:  34%|###3      | 90/268 [00:19<00:36,  4.83it/s]
03/27 07:52:46 PM ***** Running evaluation *****
03/27 07:52:46 PM   Epoch = 15 iter 4099 step
03/27 07:52:46 PM   Num examples = 1043
03/27 07:52:46 PM   Batch size = 32
03/27 07:52:46 PM ***** Eval results *****
03/27 07:52:46 PM   att_loss = 5.724208360022687
03/27 07:52:46 PM   cls_loss = 0.0
03/27 07:52:46 PM   global_step = 4099
03/27 07:52:46 PM   loss = 6.308021499755535
03/27 07:52:46 PM   rep_loss = 0.5838131340260201






Iteration:  53%|#####3    | 143/268 [00:30<00:25,  4.84it/s]
03/27 07:52:57 PM ***** Running evaluation *****
03/27 07:52:57 PM   Epoch = 15 iter 4149 step
03/27 07:52:57 PM   Num examples = 1043
03/27 07:52:57 PM   Batch size = 32
03/27 07:52:57 PM ***** Eval results *****
03/27 07:52:57 PM   att_loss = 5.7179593377643165
03/27 07:52:57 PM   cls_loss = 0.0
03/27 07:52:57 PM   global_step = 4149
03/27 07:52:57 PM   loss = 6.302254815896352
03/27 07:52:57 PM   rep_loss = 0.5842954806155629





Iteration:  71%|#######1  | 191/268 [00:41<00:15,  4.84it/s]
03/27 07:53:08 PM ***** Running evaluation *****
03/27 07:53:08 PM   Epoch = 15 iter 4199 step
03/27 07:53:08 PM   Num examples = 1043
03/27 07:53:08 PM   Batch size = 32
03/27 07:53:08 PM ***** Eval results *****
03/27 07:53:08 PM   att_loss = 5.72111948003474
03/27 07:53:08 PM   cls_loss = 0.0
03/27 07:53:08 PM   global_step = 4199
03/27 07:53:08 PM   loss = 6.305807150516314
03/27 07:53:08 PM   rep_loss = 0.584687671403295






Iteration:  91%|######### | 243/268 [00:52<00:05,  4.85it/s]
03/27 07:53:19 PM ***** Running evaluation *****
03/27 07:53:19 PM   Epoch = 15 iter 4249 step
03/27 07:53:19 PM   Num examples = 1043
03/27 07:53:19 PM   Batch size = 32
03/27 07:53:19 PM ***** Eval results *****
03/27 07:53:19 PM   att_loss = 5.7266701557597175
03/27 07:53:19 PM   cls_loss = 0.0
03/27 07:53:19 PM   global_step = 4249
03/27 07:53:19 PM   loss = 6.311379065279101
03/27 07:53:19 PM   rep_loss = 0.5847089090308205


Epoch:  53%|█████▎    | 16/30 [15:39<13:42, 58.73s/it]5it/s]


Iteration:   9%|8         | 24/268 [00:04<00:50,  4.85it/s]
03/27 07:53:30 PM ***** Running evaluation *****
03/27 07:53:30 PM   Epoch = 16 iter 4299 step
03/27 07:53:30 PM   Num examples = 1043
03/27 07:53:30 PM   Batch size = 32
03/27 07:53:30 PM ***** Eval results *****
03/27 07:53:30 PM   att_loss = 5.676726694460268
03/27 07:53:30 PM   cls_loss = 0.0
03/27 07:53:30 PM   global_step = 4299
03/27 07:53:30 PM   loss = 6.257642763632315
03/27 07:53:30 PM   rep_loss = 0.5809160735872057






Iteration:  28%|##8       | 76/268 [00:16<00:39,  4.84it/s]
03/27 07:53:41 PM ***** Running evaluation *****
03/27 07:53:41 PM   Epoch = 16 iter 4349 step
03/27 07:53:41 PM   Num examples = 1043
03/27 07:53:41 PM   Batch size = 32
03/27 07:53:41 PM ***** Eval results *****
03/27 07:53:41 PM   att_loss = 5.68604360927235
03/27 07:53:41 PM   cls_loss = 0.0
03/27 07:53:41 PM   global_step = 4349
03/27 07:53:41 PM   loss = 6.268939848070021
03/27 07:53:41 PM   rep_loss = 0.5828962411199298





Iteration:  46%|####6     | 124/268 [00:26<00:29,  4.84it/s]
03/27 07:53:52 PM ***** Running evaluation *****
03/27 07:53:52 PM   Epoch = 16 iter 4399 step
03/27 07:53:52 PM   Num examples = 1043
03/27 07:53:52 PM   Batch size = 32
03/27 07:53:52 PM ***** Eval results *****
03/27 07:53:52 PM   att_loss = 5.709334887857512
03/27 07:53:52 PM   cls_loss = 0.0
03/27 07:53:52 PM   global_step = 4399
03/27 07:53:52 PM   loss = 6.291875411206343
03/27 07:53:52 PM   rep_loss = 0.5825405205328633






Iteration:  66%|######5   | 176/268 [00:38<00:19,  4.84it/s]
03/27 07:54:03 PM ***** Running evaluation *****
03/27 07:54:03 PM   Epoch = 16 iter 4449 step
03/27 07:54:03 PM   Num examples = 1043
03/27 07:54:03 PM   Batch size = 32
03/27 07:54:03 PM ***** Eval results *****
03/27 07:54:03 PM   att_loss = 5.724728032020526
03/27 07:54:03 PM   cls_loss = 0.0
03/27 07:54:03 PM   global_step = 4449
03/27 07:54:03 PM   loss = 6.308217466214282
03/27 07:54:03 PM   rep_loss = 0.5834894240912745





Iteration:  84%|########3 | 224/268 [00:48<00:09,  4.83it/s]
03/27 07:54:14 PM ***** Running evaluation *****
03/27 07:54:14 PM   Epoch = 16 iter 4499 step
03/27 07:54:14 PM   Num examples = 1043
03/27 07:54:14 PM   Batch size = 32
03/27 07:54:14 PM ***** Eval results *****
03/27 07:54:14 PM   att_loss = 5.719954879273402
03/27 07:54:14 PM   cls_loss = 0.0
03/27 07:54:14 PM   global_step = 4499
03/27 07:54:14 PM   loss = 6.3029282250593415
03/27 07:54:14 PM   rep_loss = 0.5829733447356371




Epoch:  57%|█████▋    | 17/30 [16:38<12:42, 58.65s/it]5it/s]

Iteration:   3%|3         | 9/268 [00:01<00:53,  4.86it/s]
03/27 07:54:25 PM ***** Running evaluation *****
03/27 07:54:25 PM   Epoch = 17 iter 4549 step
03/27 07:54:25 PM   Num examples = 1043
03/27 07:54:25 PM   Batch size = 32
03/27 07:54:25 PM ***** Eval results *****
03/27 07:54:25 PM   att_loss = 5.666632080078125
03/27 07:54:25 PM   cls_loss = 0.0
03/27 07:54:25 PM   global_step = 4549
03/27 07:54:25 PM   loss = 6.243712711334228
03/27 07:54:25 PM   rep_loss = 0.5770806670188904





Iteration:  22%|##1       | 58/268 [00:12<00:43,  4.85it/s]
03/27 07:54:36 PM ***** Running evaluation *****
03/27 07:54:36 PM   Epoch = 17 iter 4599 step
03/27 07:54:36 PM   Num examples = 1043
03/27 07:54:36 PM   Batch size = 32
03/27 07:54:36 PM ***** Eval results *****
03/27 07:54:36 PM   att_loss = 5.666814557711283
03/27 07:54:36 PM   cls_loss = 0.0
03/27 07:54:36 PM   global_step = 4599
03/27 07:54:36 PM   loss = 6.24545202255249
03/27 07:54:36 PM   rep_loss = 0.5786374588807424






Iteration:  41%|####1     | 110/268 [00:24<01:05,  2.43it/s]
03/27 07:54:47 PM ***** Running evaluation *****
03/27 07:54:47 PM   Epoch = 17 iter 4649 step
03/27 07:54:47 PM   Num examples = 1043
03/27 07:54:47 PM   Batch size = 32
03/27 07:54:47 PM ***** Eval results *****
03/27 07:54:47 PM   att_loss = 5.677099054509943
03/27 07:54:47 PM   cls_loss = 0.0
03/27 07:54:47 PM   global_step = 4649
03/27 07:54:47 PM   loss = 6.256180832602761
03/27 07:54:47 PM   rep_loss = 0.579081774299795





Iteration:  59%|#####8    | 158/268 [00:34<00:22,  4.85it/s]
03/27 07:54:58 PM ***** Running evaluation *****
03/27 07:54:58 PM   Epoch = 17 iter 4699 step
03/27 07:54:58 PM   Num examples = 1043
03/27 07:54:58 PM   Batch size = 32
03/27 07:54:58 PM ***** Eval results *****
03/27 07:54:58 PM   att_loss = 5.678599202632904
03/27 07:54:58 PM   cls_loss = 0.0
03/27 07:54:58 PM   global_step = 4699
03/27 07:54:58 PM   loss = 6.2575420290231705
03/27 07:54:58 PM   rep_loss = 0.5789428155869245






Iteration:  78%|#######8  | 210/268 [00:46<00:23,  2.47it/s]
03/27 07:55:09 PM ***** Running evaluation *****
03/27 07:55:09 PM   Epoch = 17 iter 4749 step
03/27 07:55:09 PM   Num examples = 1043
03/27 07:55:09 PM   Batch size = 32
03/27 07:55:09 PM ***** Eval results *****
03/27 07:55:09 PM   att_loss = 5.6908254827771865
03/27 07:55:09 PM   cls_loss = 0.0
03/27 07:55:09 PM   global_step = 4749
03/27 07:55:09 PM   loss = 6.2703053020295645
03/27 07:55:09 PM   rep_loss = 0.5794798178332192





Iteration:  97%|#########6| 259/268 [00:56<00:01,  4.85it/s]
03/27 07:55:20 PM ***** Running evaluation *****
03/27 07:55:20 PM   Epoch = 17 iter 4799 step
03/27 07:55:20 PM   Num examples = 1043
03/27 07:55:20 PM   Batch size = 32
03/27 07:55:20 PM ***** Eval results *****
03/27 07:55:20 PM   att_loss = 5.698542008033166
03/27 07:55:20 PM   cls_loss = 0.0
03/27 07:55:20 PM   global_step = 4799
03/27 07:55:20 PM   loss = 6.277950901251573
03/27 07:55:20 PM   rep_loss = 0.5794088920721641

Epoch:  60%|██████    | 18/30 [17:37<11:45, 58.78s/it]9it/s]




Iteration:  16%|#6        | 43/268 [00:09<01:32,  2.43it/s]
03/27 07:55:31 PM ***** Running evaluation *****
03/27 07:55:31 PM   Epoch = 18 iter 4849 step
03/27 07:55:31 PM   Num examples = 1043
03/27 07:55:31 PM   Batch size = 32
03/27 07:55:31 PM ***** Eval results *****
03/27 07:55:31 PM   att_loss = 5.705206272213958
03/27 07:55:31 PM   cls_loss = 0.0
03/27 07:55:31 PM   global_step = 4849
03/27 07:55:31 PM   loss = 6.282907607943513
03/27 07:55:31 PM   rep_loss = 0.5777013592941816





Iteration:  34%|###4      | 92/268 [00:19<00:36,  4.85it/s]
03/27 07:55:42 PM ***** Running evaluation *****
03/27 07:55:42 PM   Epoch = 18 iter 4899 step
03/27 07:55:42 PM   Num examples = 1043
03/27 07:55:42 PM   Batch size = 32
03/27 07:55:42 PM ***** Eval results *****
03/27 07:55:42 PM   att_loss = 5.683933437511485
03/27 07:55:42 PM   cls_loss = 0.0
03/27 07:55:42 PM   global_step = 4899
03/27 07:55:42 PM   loss = 6.260590286665066
03/27 07:55:42 PM   rep_loss = 0.5766568549217717






Iteration:  54%|#####3    | 144/268 [00:31<00:43,  2.87it/s]
03/27 07:55:53 PM ***** Running evaluation *****
03/27 07:55:53 PM   Epoch = 18 iter 4949 step
03/27 07:55:53 PM   Num examples = 1043
03/27 07:55:53 PM   Batch size = 32
03/27 07:55:53 PM ***** Eval results *****
03/27 07:55:53 PM   att_loss = 5.657147204125677
03/27 07:55:53 PM   cls_loss = 0.0
03/27 07:55:53 PM   global_step = 4949
03/27 07:55:53 PM   loss = 6.233906969323859
03/27 07:55:53 PM   rep_loss = 0.5767597606132081





Iteration:  72%|#######1  | 192/268 [00:41<00:15,  4.86it/s]
03/27 07:56:04 PM ***** Running evaluation *****
03/27 07:56:04 PM   Epoch = 18 iter 4999 step
03/27 07:56:04 PM   Num examples = 1043
03/27 07:56:04 PM   Batch size = 32
03/27 07:56:04 PM ***** Eval results *****
03/27 07:56:04 PM   att_loss = 5.658307942701745
03/27 07:56:04 PM   cls_loss = 0.0
03/27 07:56:04 PM   global_step = 4999
03/27 07:56:04 PM   loss = 6.2357436239410555
03/27 07:56:04 PM   rep_loss = 0.5774356787686521






Iteration:  91%|#########1| 244/268 [00:53<00:08,  2.86it/s]
03/27 07:56:15 PM ***** Running evaluation *****
03/27 07:56:15 PM   Epoch = 18 iter 5049 step
03/27 07:56:15 PM   Num examples = 1043
03/27 07:56:15 PM   Batch size = 32
03/27 07:56:15 PM ***** Eval results *****
03/27 07:56:15 PM   att_loss = 5.6718649255886
03/27 07:56:15 PM   cls_loss = 0.0
03/27 07:56:15 PM   global_step = 5049
03/27 07:56:15 PM   loss = 6.249477504212179
03/27 07:56:15 PM   rep_loss = 0.577612580095299


Epoch:  63%|██████▎   | 19/30 [18:35<10:45, 58.66s/it]5it/s]


Iteration:   9%|9         | 25/268 [00:05<00:50,  4.85it/s]
03/27 07:56:26 PM ***** Running evaluation *****
03/27 07:56:26 PM   Epoch = 19 iter 5099 step
03/27 07:56:26 PM   Num examples = 1043
03/27 07:56:26 PM   Batch size = 32
03/27 07:56:26 PM ***** Eval results *****
03/27 07:56:26 PM   att_loss = 5.681360134711633
03/27 07:56:26 PM   cls_loss = 0.0
03/27 07:56:26 PM   global_step = 5099
03/27 07:56:26 PM   loss = 6.254759476735042
03/27 07:56:26 PM   rep_loss = 0.5733993351459503






Iteration:  29%|##9       | 78/268 [00:17<00:57,  3.28it/s]
03/27 07:56:37 PM ***** Running evaluation *****
03/27 07:56:37 PM   Epoch = 19 iter 5149 step
03/27 07:56:37 PM   Num examples = 1043
03/27 07:56:37 PM   Batch size = 32
03/27 07:56:37 PM ***** Eval results *****
03/27 07:56:37 PM   att_loss = 5.627581295214202
03/27 07:56:37 PM   cls_loss = 0.0
03/27 07:56:37 PM   global_step = 5149
03/27 07:56:37 PM   loss = 6.199470883921573
03/27 07:56:37 PM   rep_loss = 0.5718895847860136





Iteration:  47%|####6     | 125/268 [00:27<00:29,  4.85it/s]
03/27 07:56:48 PM ***** Running evaluation *****
03/27 07:56:48 PM   Epoch = 19 iter 5199 step
03/27 07:56:48 PM   Num examples = 1043
03/27 07:56:48 PM   Batch size = 32
03/27 07:56:48 PM ***** Eval results *****
03/27 07:56:48 PM   att_loss = 5.637446494329543
03/27 07:56:48 PM   cls_loss = 0.0
03/27 07:56:48 PM   global_step = 5199
03/27 07:56:48 PM   loss = 6.2100896456884955
03/27 07:56:48 PM   rep_loss = 0.5726431366943178





Iteration:  64%|######4   | 172/268 [00:37<00:19,  4.86it/s]
03/27 07:56:59 PM ***** Running evaluation *****
03/27 07:56:59 PM   Epoch = 19 iter 5249 step
03/27 07:56:59 PM   Num examples = 1043
03/27 07:56:59 PM   Batch size = 32
03/27 07:56:59 PM ***** Eval results *****
03/27 07:56:59 PM   att_loss = 5.65401131998409
03/27 07:56:59 PM   cls_loss = 0.0
03/27 07:56:59 PM   global_step = 5249
03/27 07:56:59 PM   loss = 6.22770064256408
03/27 07:56:59 PM   rep_loss = 0.5736893002282489






Iteration:  84%|########3 | 225/268 [00:49<00:08,  4.84it/s]
03/27 07:57:10 PM ***** Running evaluation *****
03/27 07:57:10 PM   Epoch = 19 iter 5299 step
03/27 07:57:10 PM   Num examples = 1043
03/27 07:57:10 PM   Batch size = 32
03/27 07:57:10 PM ***** Eval results *****
03/27 07:57:10 PM   att_loss = 5.655241997896042
03/27 07:57:10 PM   cls_loss = 0.0
03/27 07:57:10 PM   global_step = 5299
03/27 07:57:10 PM   loss = 6.229768107422685
03/27 07:57:10 PM   rep_loss = 0.5745260889551281




Epoch:  67%|██████▋   | 20/30 [19:34<09:45, 58.57s/it]6it/s]
Iteration:   1%|1         | 3/268 [00:00<00:54,  4.85it/s]
03/27 07:57:21 PM ***** Running evaluation *****
03/27 07:57:21 PM   Epoch = 20 iter 5349 step
03/27 07:57:21 PM   Num examples = 1043
03/27 07:57:21 PM   Batch size = 32
03/27 07:57:21 PM ***** Eval results *****
03/27 07:57:21 PM   att_loss = 5.621240191989475
03/27 07:57:21 PM   cls_loss = 0.0
03/27 07:57:21 PM   global_step = 5349
03/27 07:57:21 PM   loss = 6.19248718685574
03/27 07:57:21 PM   rep_loss = 0.5712471074528165






Iteration:  22%|##1       | 58/268 [00:12<00:43,  4.84it/s]
03/27 07:57:32 PM ***** Running evaluation *****
03/27 07:57:32 PM   Epoch = 20 iter 5399 step
03/27 07:57:32 PM   Num examples = 1043
03/27 07:57:32 PM   Batch size = 32
03/27 07:57:32 PM ***** Eval results *****
03/27 07:57:32 PM   att_loss = 5.607511859829143
03/27 07:57:32 PM   cls_loss = 0.0
03/27 07:57:32 PM   global_step = 5399
03/27 07:57:32 PM   loss = 6.180335828813456
03/27 07:57:32 PM   rep_loss = 0.5728239619125755





Iteration:  38%|###8      | 103/268 [00:22<00:34,  4.85it/s]
03/27 07:57:43 PM ***** Running evaluation *****
03/27 07:57:43 PM   Epoch = 20 iter 5449 step
03/27 07:57:43 PM   Num examples = 1043
03/27 07:57:43 PM   Batch size = 32
03/27 07:57:43 PM ***** Eval results *****
03/27 07:57:43 PM   att_loss = 5.620653060598111
03/27 07:57:43 PM   cls_loss = 0.0
03/27 07:57:43 PM   global_step = 5449
03/27 07:57:43 PM   loss = 6.1939080702055485
03/27 07:57:43 PM   rep_loss = 0.5732550216377328






Iteration:  59%|#####8    | 158/268 [00:34<00:22,  4.84it/s]
03/27 07:57:54 PM ***** Running evaluation *****
03/27 07:57:54 PM   Epoch = 20 iter 5499 step
03/27 07:57:54 PM   Num examples = 1043
03/27 07:57:54 PM   Batch size = 32
03/27 07:57:54 PM ***** Eval results *****
03/27 07:57:54 PM   att_loss = 5.6155187528838155
03/27 07:57:54 PM   cls_loss = 0.0
03/27 07:57:54 PM   global_step = 5499
03/27 07:57:54 PM   loss = 6.188683605793887
03/27 07:57:54 PM   rep_loss = 0.5731648604075114





Iteration:  76%|#######6  | 204/268 [00:44<00:13,  4.85it/s]
03/27 07:58:05 PM ***** Running evaluation *****
03/27 07:58:05 PM   Epoch = 20 iter 5549 step
03/27 07:58:05 PM   Num examples = 1043
03/27 07:58:05 PM   Batch size = 32
03/27 07:58:05 PM ***** Eval results *****
03/27 07:58:05 PM   att_loss = 5.627147715627862
03/27 07:58:05 PM   cls_loss = 0.0
03/27 07:58:05 PM   global_step = 5549
03/27 07:58:05 PM   loss = 6.200652115653006
03/27 07:58:05 PM   rep_loss = 0.5735044100067832






Iteration:  96%|#########6| 258/268 [00:56<00:02,  4.85it/s]
03/27 07:58:16 PM ***** Running evaluation *****
03/27 07:58:16 PM   Epoch = 20 iter 5599 step
03/27 07:58:16 PM   Num examples = 1043
03/27 07:58:16 PM   Batch size = 32
03/27 07:58:16 PM ***** Eval results *****
03/27 07:58:16 PM   att_loss = 5.62627209659709
03/27 07:58:16 PM   cls_loss = 0.0
03/27 07:58:16 PM   global_step = 5599
03/27 07:58:16 PM   loss = 6.1997835571701465
03/27 07:58:16 PM   rep_loss = 0.5735114674770694

Epoch:  70%|███████   | 21/30 [20:33<08:48, 58.74s/it]9it/s]



Iteration:  14%|#3        | 37/268 [00:07<00:47,  4.85it/s]
03/27 07:58:27 PM ***** Running evaluation *****
03/27 07:58:27 PM   Epoch = 21 iter 5649 step
03/27 07:58:27 PM   Num examples = 1043
03/27 07:58:27 PM   Batch size = 32
03/27 07:58:27 PM ***** Eval results *****
03/27 07:58:27 PM   att_loss = 5.642954678762527
03/27 07:58:27 PM   cls_loss = 0.0
03/27 07:58:27 PM   global_step = 5649
03/27 07:58:27 PM   loss = 6.214937096550351
03/27 07:58:27 PM   rep_loss = 0.5719824504284632






Iteration:  34%|###3      | 91/268 [00:19<00:36,  4.85it/s]
03/27 07:58:38 PM ***** Running evaluation *****
03/27 07:58:38 PM   Epoch = 21 iter 5699 step
03/27 07:58:38 PM   Num examples = 1043
03/27 07:58:38 PM   Batch size = 32
03/27 07:58:38 PM ***** Eval results *****
03/27 07:58:38 PM   att_loss = 5.634216158286385
03/27 07:58:38 PM   cls_loss = 0.0
03/27 07:58:38 PM   global_step = 5699
03/27 07:58:38 PM   loss = 6.20721627836642
03/27 07:58:38 PM   rep_loss = 0.5730001323896906





Iteration:  51%|#####1    | 137/268 [00:29<00:27,  4.85it/s]
03/27 07:58:49 PM ***** Running evaluation *****
03/27 07:58:49 PM   Epoch = 21 iter 5749 step
03/27 07:58:49 PM   Num examples = 1043
03/27 07:58:49 PM   Batch size = 32
03/27 07:58:49 PM ***** Eval results *****
03/27 07:58:49 PM   att_loss = 5.617748139609753
03/27 07:58:49 PM   cls_loss = 0.0
03/27 07:58:49 PM   global_step = 5749
03/27 07:58:49 PM   loss = 6.189682698585618
03/27 07:58:49 PM   rep_loss = 0.5719345619141216






Iteration:  71%|#######1  | 191/268 [00:41<00:15,  4.84it/s]
03/27 07:59:00 PM ***** Running evaluation *****
03/27 07:59:00 PM   Epoch = 21 iter 5799 step
03/27 07:59:00 PM   Num examples = 1043
03/27 07:59:00 PM   Batch size = 32
03/27 07:59:00 PM ***** Eval results *****
03/27 07:59:00 PM   att_loss = 5.623003828028838
03/27 07:59:00 PM   cls_loss = 0.0
03/27 07:59:00 PM   global_step = 5799
03/27 07:59:00 PM   loss = 6.195223820706208
03/27 07:59:00 PM   rep_loss = 0.5722199967131019





Iteration:  88%|########8 | 237/268 [00:51<00:06,  4.85it/s]
03/27 07:59:11 PM ***** Running evaluation *****
03/27 07:59:11 PM   Epoch = 21 iter 5849 step
03/27 07:59:11 PM   Num examples = 1043
03/27 07:59:11 PM   Batch size = 32
03/27 07:59:11 PM ***** Eval results *****
03/27 07:59:11 PM   att_loss = 5.625903848774177
03/27 07:59:11 PM   cls_loss = 0.0
03/27 07:59:11 PM   global_step = 5849
03/27 07:59:11 PM   loss = 6.198202996214559
03/27 07:59:11 PM   rep_loss = 0.5722991535978869



Epoch:  73%|███████▎  | 22/30 [21:31<07:49, 58.65s/it]6it/s]


Iteration:   9%|8         | 24/268 [00:04<00:50,  4.86it/s]
03/27 07:59:22 PM ***** Running evaluation *****
03/27 07:59:22 PM   Epoch = 22 iter 5899 step
03/27 07:59:22 PM   Num examples = 1043
03/27 07:59:22 PM   Batch size = 32
03/27 07:59:22 PM ***** Eval results *****
03/27 07:59:22 PM   att_loss = 5.543636627197266
03/27 07:59:22 PM   cls_loss = 0.0
03/27 07:59:22 PM   global_step = 5899
03/27 07:59:22 PM   loss = 6.1125295448303225
03/27 07:59:22 PM   rep_loss = 0.5688929176330566





Iteration:  26%|##6       | 71/268 [00:15<00:40,  4.84it/s]
03/27 07:59:33 PM ***** Running evaluation *****
03/27 07:59:33 PM   Epoch = 22 iter 5949 step
03/27 07:59:33 PM   Num examples = 1043
03/27 07:59:33 PM   Batch size = 32
03/27 07:59:33 PM ***** Eval results *****
03/27 07:59:33 PM   att_loss = 5.578014055887858
03/27 07:59:33 PM   cls_loss = 0.0
03/27 07:59:33 PM   global_step = 5949
03/27 07:59:33 PM   loss = 6.145613435109456
03/27 07:59:33 PM   rep_loss = 0.5675993673006694






Iteration:  46%|####6     | 124/268 [00:26<00:29,  4.85it/s]
03/27 07:59:44 PM ***** Running evaluation *****
03/27 07:59:44 PM   Epoch = 22 iter 5999 step
03/27 07:59:44 PM   Num examples = 1043
03/27 07:59:44 PM   Batch size = 32
03/27 07:59:44 PM ***** Eval results *****
03/27 07:59:44 PM   att_loss = 5.588450687408447
03/27 07:59:44 PM   cls_loss = 0.0
03/27 07:59:44 PM   global_step = 5999
03/27 07:59:44 PM   loss = 6.157205261230469
03/27 07:59:44 PM   rep_loss = 0.5687545557022095





Iteration:  64%|######3   | 171/268 [00:37<00:19,  4.85it/s]
03/27 07:59:55 PM ***** Running evaluation *****
03/27 07:59:55 PM   Epoch = 22 iter 6049 step
03/27 07:59:55 PM   Num examples = 1043
03/27 07:59:55 PM   Batch size = 32
03/27 07:59:55 PM ***** Eval results *****
03/27 07:59:55 PM   att_loss = 5.597875249045236
03/27 07:59:55 PM   cls_loss = 0.0
03/27 07:59:55 PM   global_step = 6049
03/27 07:59:55 PM   loss = 6.167363125937325
03/27 07:59:55 PM   rep_loss = 0.5694878687177386






Iteration:  84%|########3 | 224/268 [00:48<00:09,  4.85it/s]
03/27 08:00:06 PM ***** Running evaluation *****
03/27 08:00:06 PM   Epoch = 22 iter 6099 step
03/27 08:00:06 PM   Num examples = 1043
03/27 08:00:06 PM   Batch size = 32
03/27 08:00:06 PM ***** Eval results *****
03/27 08:00:06 PM   att_loss = 5.609352277119954
03/27 08:00:06 PM   cls_loss = 0.0
03/27 08:00:06 PM   global_step = 6099
03/27 08:00:06 PM   loss = 6.1791061825222435
03/27 08:00:06 PM   rep_loss = 0.5697538918919034




Epoch:  77%|███████▋  | 23/30 [22:29<06:49, 58.57s/it]6it/s]
Iteration:   2%|1         | 5/268 [00:01<00:54,  4.86it/s]
03/27 08:00:17 PM ***** Running evaluation *****
03/27 08:00:17 PM   Epoch = 23 iter 6149 step
03/27 08:00:17 PM   Num examples = 1043
03/27 08:00:17 PM   Batch size = 32
03/27 08:00:17 PM ***** Eval results *****
03/27 08:00:17 PM   att_loss = 5.575234055519104
03/27 08:00:17 PM   cls_loss = 0.0
03/27 08:00:17 PM   global_step = 6149
03/27 08:00:17 PM   loss = 6.142765522003174
03/27 08:00:17 PM   rep_loss = 0.567531481385231






Iteration:  21%|##1       | 57/268 [00:12<00:43,  4.85it/s]
03/27 08:00:28 PM ***** Running evaluation *****
03/27 08:00:28 PM   Epoch = 23 iter 6199 step
03/27 08:00:28 PM   Num examples = 1043
03/27 08:00:28 PM   Batch size = 32
03/27 08:00:28 PM ***** Eval results *****
03/27 08:00:28 PM   att_loss = 5.591453881099306
03/27 08:00:28 PM   cls_loss = 0.0
03/27 08:00:28 PM   global_step = 6199
03/27 08:00:28 PM   loss = 6.161307976163667
03/27 08:00:28 PM   rep_loss = 0.5698540888983628





Iteration:  39%|###9      | 105/268 [00:22<00:33,  4.85it/s]
03/27 08:00:39 PM ***** Running evaluation *****
03/27 08:00:39 PM   Epoch = 23 iter 6249 step
03/27 08:00:39 PM   Num examples = 1043
03/27 08:00:39 PM   Batch size = 32
03/27 08:00:39 PM ***** Eval results *****
03/27 08:00:39 PM   att_loss = 5.609604990040815
03/27 08:00:39 PM   cls_loss = 0.0
03/27 08:00:39 PM   global_step = 6249
03/27 08:00:39 PM   loss = 6.179203474963153
03/27 08:00:39 PM   rep_loss = 0.569598486578023






Iteration:  59%|#####8    | 157/268 [00:34<00:22,  4.84it/s]
03/27 08:00:50 PM ***** Running evaluation *****
03/27 08:00:50 PM   Epoch = 23 iter 6299 step
03/27 08:00:50 PM   Num examples = 1043
03/27 08:00:50 PM   Batch size = 32
03/27 08:00:50 PM ***** Eval results *****
03/27 08:00:50 PM   att_loss = 5.603661778606946
03/27 08:00:50 PM   cls_loss = 0.0
03/27 08:00:50 PM   global_step = 6299
03/27 08:00:50 PM   loss = 6.173219581193562
03/27 08:00:50 PM   rep_loss = 0.5695578033411051





Iteration:  77%|#######6  | 206/268 [00:45<00:12,  4.85it/s]
03/27 08:01:01 PM ***** Running evaluation *****
03/27 08:01:01 PM   Epoch = 23 iter 6349 step
03/27 08:01:01 PM   Num examples = 1043
03/27 08:01:01 PM   Batch size = 32
03/27 08:01:01 PM ***** Eval results *****
03/27 08:01:01 PM   att_loss = 5.605193355908761
03/27 08:01:01 PM   cls_loss = 0.0
03/27 08:01:01 PM   global_step = 6349
03/27 08:01:01 PM   loss = 6.17435478247129
03/27 08:01:01 PM   rep_loss = 0.5691614294281373






Iteration:  96%|#########5| 257/268 [00:56<00:02,  4.85it/s]
03/27 08:01:12 PM ***** Running evaluation *****
03/27 08:01:12 PM   Epoch = 23 iter 6399 step
03/27 08:01:12 PM   Num examples = 1043
03/27 08:01:12 PM   Batch size = 32
03/27 08:01:12 PM ***** Eval results *****
03/27 08:01:12 PM   att_loss = 5.605484178824018
03/27 08:01:12 PM   cls_loss = 0.0
03/27 08:01:12 PM   global_step = 6399
03/27 08:01:12 PM   loss = 6.17476055049157
03/27 08:01:12 PM   rep_loss = 0.5692763679711393
Epoch:  80%|████████  | 24/30 [23:29<05:52, 58.71s/it]7it/s]




Iteration:  15%|#4        | 39/268 [00:08<00:47,  4.85it/s]
03/27 08:01:23 PM ***** Running evaluation *****
03/27 08:01:23 PM   Epoch = 24 iter 6449 step
03/27 08:01:23 PM   Num examples = 1043
03/27 08:01:23 PM   Batch size = 32
03/27 08:01:23 PM ***** Eval results *****
03/27 08:01:23 PM   att_loss = 5.568025530838385
03/27 08:01:23 PM   cls_loss = 0.0
03/27 08:01:23 PM   global_step = 6449
03/27 08:01:23 PM   loss = 6.133130678316442
03/27 08:01:23 PM   rep_loss = 0.5651051213101643






Iteration:  34%|###3      | 91/268 [00:20<01:11,  2.48it/s]
03/27 08:01:34 PM ***** Running evaluation *****
03/27 08:01:34 PM   Epoch = 24 iter 6499 step
03/27 08:01:34 PM   Num examples = 1043
03/27 08:01:34 PM   Batch size = 32
03/27 08:01:34 PM ***** Eval results *****
03/27 08:01:34 PM   att_loss = 5.57333747109214
03/27 08:01:34 PM   cls_loss = 0.0
03/27 08:01:34 PM   global_step = 6499
03/27 08:01:34 PM   loss = 6.139049592908922
03/27 08:01:34 PM   rep_loss = 0.56571210871686





Iteration:  52%|#####1    | 139/268 [00:29<00:26,  4.84it/s]
03/27 08:01:45 PM ***** Running evaluation *****
03/27 08:01:45 PM   Epoch = 24 iter 6549 step
03/27 08:01:45 PM   Num examples = 1043
03/27 08:01:45 PM   Batch size = 32
03/27 08:01:45 PM ***** Eval results *****
03/27 08:01:45 PM   att_loss = 5.558728529206404
03/27 08:01:45 PM   cls_loss = 0.0
03/27 08:01:45 PM   global_step = 6549
03/27 08:01:45 PM   loss = 6.124524197679885
03/27 08:01:45 PM   rep_loss = 0.5657956519870894






Iteration:  71%|#######1  | 191/268 [00:42<00:30,  2.51it/s]
03/27 08:01:55 PM ***** Running evaluation *****
03/27 08:01:55 PM   Epoch = 24 iter 6599 step
03/27 08:01:55 PM   Num examples = 1043
03/27 08:01:56 PM   Batch size = 32
03/27 08:01:56 PM ***** Eval results *****
03/27 08:01:56 PM   att_loss = 5.576021381697729
03/27 08:01:56 PM   cls_loss = 0.0
03/27 08:01:56 PM   global_step = 6599
03/27 08:01:56 PM   loss = 6.142751925902841
03/27 08:01:56 PM   rep_loss = 0.5667305254811392





Iteration:  90%|########9 | 240/268 [00:52<00:05,  4.85it/s]
03/27 08:02:06 PM ***** Running evaluation *****
03/27 08:02:06 PM   Epoch = 24 iter 6649 step
03/27 08:02:06 PM   Num examples = 1043
03/27 08:02:06 PM   Batch size = 32
03/27 08:02:06 PM ***** Eval results *****
03/27 08:02:06 PM   att_loss = 5.582732899060388
03/27 08:02:06 PM   cls_loss = 0.0
03/27 08:02:06 PM   global_step = 6649
03/27 08:02:06 PM   loss = 6.149561808811678
03/27 08:02:06 PM   rep_loss = 0.5668288976325039



Epoch:  83%|████████▎ | 25/30 [24:27<04:53, 58.61s/it]9it/s]

Iteration:   7%|6         | 18/268 [00:03<00:51,  4.86it/s]
03/27 08:02:17 PM ***** Running evaluation *****
03/27 08:02:17 PM   Epoch = 25 iter 6699 step
03/27 08:02:17 PM   Num examples = 1043
03/27 08:02:17 PM   Batch size = 32
03/27 08:02:17 PM ***** Eval results *****
03/27 08:02:17 PM   att_loss = 5.52633132537206
03/27 08:02:17 PM   cls_loss = 0.0
03/27 08:02:17 PM   global_step = 6699

Iteration:   9%|9         | 25/268 [00:05<01:26,  2.81it/s]
03/27 08:02:17 PM   rep_loss = 0.567464883128802





Iteration:  27%|##7       | 73/268 [00:15<00:40,  4.86it/s]
03/27 08:02:28 PM ***** Running evaluation *****
03/27 08:02:28 PM   Epoch = 25 iter 6749 step
03/27 08:02:28 PM   Num examples = 1043
03/27 08:02:28 PM   Batch size = 32
03/27 08:02:28 PM ***** Eval results *****
03/27 08:02:28 PM   att_loss = 5.556440514487189
03/27 08:02:28 PM   cls_loss = 0.0
03/27 08:02:28 PM   global_step = 6749
03/27 08:02:28 PM   loss = 6.124020106083638
03/27 08:02:28 PM   rep_loss = 0.5675795569613173





Iteration:  44%|####4     | 119/268 [00:25<00:30,  4.84it/s]
03/27 08:02:39 PM ***** Running evaluation *****
03/27 08:02:39 PM   Epoch = 25 iter 6799 step
03/27 08:02:39 PM   Num examples = 1043
03/27 08:02:39 PM   Batch size = 32
03/27 08:02:39 PM ***** Eval results *****
03/27 08:02:39 PM   att_loss = 5.553213488671087
03/27 08:02:39 PM   cls_loss = 0.0
03/27 08:02:39 PM   global_step = 6799
03/27 08:02:39 PM   loss = 6.119289244374921

Iteration:  47%|####6     | 125/268 [00:27<00:49,  2.86it/s]





Iteration:  65%|######4   | 173/268 [00:37<00:19,  4.86it/s]
03/27 08:02:50 PM ***** Running evaluation *****
03/27 08:02:50 PM   Epoch = 25 iter 6849 step
03/27 08:02:50 PM   Num examples = 1043
03/27 08:02:50 PM   Batch size = 32
03/27 08:02:50 PM ***** Eval results *****
03/27 08:02:50 PM   att_loss = 5.554388218912585
03/27 08:02:50 PM   cls_loss = 0.0
03/27 08:02:50 PM   global_step = 6849
03/27 08:02:50 PM   loss = 6.120196361651366
03/27 08:02:50 PM   rep_loss = 0.565808119787567





Iteration:  82%|########1 | 219/268 [00:47<00:10,  4.84it/s]
03/27 08:03:01 PM ***** Running evaluation *****
03/27 08:03:01 PM   Epoch = 25 iter 6899 step
03/27 08:03:01 PM   Num examples = 1043
03/27 08:03:01 PM   Batch size = 32
03/27 08:03:01 PM ***** Eval results *****
03/27 08:03:01 PM   att_loss = 5.5580557861498425
03/27 08:03:01 PM   cls_loss = 0.0
03/27 08:03:01 PM   global_step = 6899
03/27 08:03:01 PM   loss = 6.12360500224999
03/27 08:03:01 PM   rep_loss = 0.5655491988041571





Epoch:  87%|████████▋ | 26/30 [25:25<03:54, 58.56s/it]4it/s]
Iteration:   2%|2         | 6/268 [00:01<00:54,  4.84it/s]
03/27 08:03:12 PM ***** Running evaluation *****
03/27 08:03:12 PM   Epoch = 26 iter 6949 step
03/27 08:03:12 PM   Num examples = 1043
03/27 08:03:12 PM   Batch size = 32
03/27 08:03:12 PM ***** Eval results *****
03/27 08:03:12 PM   att_loss = 5.515415804726737
03/27 08:03:12 PM   cls_loss = 0.0
03/27 08:03:12 PM   global_step = 6949
03/27 08:03:12 PM   loss = 6.074801104409354
03/27 08:03:12 PM   rep_loss = 0.5593853678022113





Iteration:  19%|#9        | 52/268 [00:11<00:44,  4.85it/s]
03/27 08:03:23 PM ***** Running evaluation *****
03/27 08:03:23 PM   Epoch = 26 iter 6999 step
03/27 08:03:23 PM   Num examples = 1043
03/27 08:03:23 PM   Batch size = 32
03/27 08:03:23 PM ***** Eval results *****
03/27 08:03:23 PM   att_loss = 5.567864844673558
03/27 08:03:23 PM   cls_loss = 0.0
03/27 08:03:23 PM   global_step = 6999
03/27 08:03:23 PM   loss = 6.133159796396892
03/27 08:03:23 PM   rep_loss = 0.5652949433577689






Iteration:  40%|###9      | 106/268 [00:23<00:33,  4.84it/s]
03/27 08:03:34 PM ***** Running evaluation *****
03/27 08:03:34 PM   Epoch = 26 iter 7049 step
03/27 08:03:34 PM   Num examples = 1043
03/27 08:03:34 PM   Batch size = 32
03/27 08:03:34 PM ***** Eval results *****
03/27 08:03:34 PM   att_loss = 5.5680177412300464
03/27 08:03:34 PM   cls_loss = 0.0
03/27 08:03:34 PM   global_step = 7049
03/27 08:03:34 PM   loss = 6.132652380756128
03/27 08:03:34 PM   rep_loss = 0.5646346450966095





Iteration:  57%|#####7    | 153/268 [00:33<00:23,  4.82it/s]
03/27 08:03:45 PM ***** Running evaluation *****
03/27 08:03:45 PM   Epoch = 26 iter 7099 step
03/27 08:03:45 PM   Num examples = 1043
03/27 08:03:45 PM   Batch size = 32
03/27 08:03:45 PM ***** Eval results *****
03/27 08:03:45 PM   att_loss = 5.561522417007738
03/27 08:03:45 PM   cls_loss = 0.0
03/27 08:03:45 PM   global_step = 7099
03/27 08:03:45 PM   loss = 6.126147303611609
03/27 08:03:45 PM   rep_loss = 0.5646248957154097






Iteration:  77%|#######6  | 206/268 [00:45<00:12,  4.85it/s]
03/27 08:03:56 PM ***** Running evaluation *****
03/27 08:03:56 PM   Epoch = 26 iter 7149 step
03/27 08:03:56 PM   Num examples = 1043
03/27 08:03:56 PM   Batch size = 32
03/27 08:03:56 PM ***** Eval results *****
03/27 08:03:56 PM   att_loss = 5.55961495321154
03/27 08:03:56 PM   cls_loss = 0.0
03/27 08:03:56 PM   global_step = 7149
03/27 08:03:56 PM   loss = 6.124359727481713
03/27 08:03:56 PM   rep_loss = 0.56474477858935





Iteration:  94%|#########4| 253/268 [00:55<00:03,  4.85it/s]
03/27 08:04:07 PM ***** Running evaluation *****
03/27 08:04:07 PM   Epoch = 26 iter 7199 step
03/27 08:04:07 PM   Num examples = 1043
03/27 08:04:07 PM   Batch size = 32
03/27 08:04:07 PM ***** Eval results *****
03/27 08:04:07 PM   att_loss = 5.563316449117104
03/27 08:04:07 PM   cls_loss = 0.0
03/27 08:04:07 PM   global_step = 7199
03/27 08:04:07 PM   loss = 6.128015297396174
03/27 08:04:07 PM   rep_loss = 0.5646988492067686

Epoch:  90%|█████████ | 27/30 [26:24<02:56, 58.72s/it]2it/s]




Iteration:  15%|#4        | 39/268 [00:08<00:47,  4.86it/s]
03/27 08:04:18 PM ***** Running evaluation *****
03/27 08:04:18 PM   Epoch = 27 iter 7249 step
03/27 08:04:18 PM   Num examples = 1043
03/27 08:04:18 PM   Batch size = 32
03/27 08:04:18 PM ***** Eval results *****
03/27 08:04:18 PM   att_loss = 5.616893720626831
03/27 08:04:18 PM   cls_loss = 0.0
03/27 08:04:18 PM   global_step = 7249
03/27 08:04:18 PM   loss = 6.180864107608795
03/27 08:04:18 PM   rep_loss = 0.563970360159874





Iteration:  32%|###2      | 87/268 [00:18<00:37,  4.85it/s]
03/27 08:04:29 PM ***** Running evaluation *****
03/27 08:04:29 PM   Epoch = 27 iter 7299 step
03/27 08:04:29 PM   Num examples = 1043
03/27 08:04:29 PM   Batch size = 32
03/27 08:04:29 PM ***** Eval results *****
03/27 08:04:29 PM   att_loss = 5.5814098252190485
03/27 08:04:29 PM   cls_loss = 0.0
03/27 08:04:29 PM   global_step = 7299
03/27 08:04:29 PM   loss = 6.1460595766703285
03/27 08:04:29 PM   rep_loss = 0.5646497236357795






Iteration:  52%|#####1    | 139/268 [00:29<00:26,  4.86it/s]
03/27 08:04:40 PM ***** Running evaluation *****
03/27 08:04:40 PM   Epoch = 27 iter 7349 step
03/27 08:04:40 PM   Num examples = 1043
03/27 08:04:40 PM   Batch size = 32
03/27 08:04:40 PM ***** Eval results *****
03/27 08:04:40 PM   att_loss = 5.550870656967163
03/27 08:04:40 PM   cls_loss = 0.0
03/27 08:04:40 PM   global_step = 7349
03/27 08:04:40 PM   loss = 6.114003079278128
03/27 08:04:40 PM   rep_loss = 0.5631324027265822





Iteration:  70%|######9   | 187/268 [00:40<00:16,  4.87it/s]
03/27 08:04:51 PM ***** Running evaluation *****
03/27 08:04:51 PM   Epoch = 27 iter 7399 step
03/27 08:04:51 PM   Num examples = 1043
03/27 08:04:51 PM   Batch size = 32
03/27 08:04:51 PM ***** Eval results *****
03/27 08:04:51 PM   att_loss = 5.562000081413671
03/27 08:04:51 PM   cls_loss = 0.0
03/27 08:04:51 PM   global_step = 7399
03/27 08:04:51 PM   loss = 6.1259589797572085
03/27 08:04:51 PM   rep_loss = 0.5639588817169792






Iteration:  89%|########9 | 239/268 [00:51<00:05,  4.85it/s]
03/27 08:05:02 PM ***** Running evaluation *****
03/27 08:05:02 PM   Epoch = 27 iter 7449 step
03/27 08:05:02 PM   Num examples = 1043
03/27 08:05:02 PM   Batch size = 32
03/27 08:05:02 PM ***** Eval results *****
03/27 08:05:02 PM   att_loss = 5.557596542437872
03/27 08:05:02 PM   cls_loss = 0.0
03/27 08:05:02 PM   global_step = 7449
03/27 08:05:02 PM   loss = 6.121345694859823
03/27 08:05:02 PM   rep_loss = 0.5637491419911385


Epoch:  93%|█████████▎| 28/30 [27:23<01:57, 58.61s/it]4it/s]


Iteration:   8%|7         | 21/268 [00:04<00:50,  4.86it/s]
03/27 08:05:13 PM ***** Running evaluation *****
03/27 08:05:13 PM   Epoch = 28 iter 7499 step
03/27 08:05:13 PM   Num examples = 1043
03/27 08:05:13 PM   Batch size = 32
03/27 08:05:13 PM ***** Eval results *****
03/27 08:05:13 PM   att_loss = 5.543043903682543
03/27 08:05:13 PM   cls_loss = 0.0
03/27 08:05:13 PM   global_step = 7499
03/27 08:05:13 PM   loss = 6.10528796652089
03/27 08:05:13 PM   rep_loss = 0.5622440498808156






Iteration:  27%|##6       | 72/268 [00:15<00:40,  4.85it/s]
03/27 08:05:24 PM ***** Running evaluation *****
03/27 08:05:24 PM   Epoch = 28 iter 7549 step
03/27 08:05:24 PM   Num examples = 1043
03/27 08:05:24 PM   Batch size = 32
03/27 08:05:24 PM ***** Eval results *****
03/27 08:05:24 PM   att_loss = 5.551909492440419
03/27 08:05:24 PM   cls_loss = 0.0
03/27 08:05:24 PM   global_step = 7549
03/27 08:05:24 PM   loss = 6.115502945364338
03/27 08:05:24 PM   rep_loss = 0.563593428428859





Iteration:  45%|####5     | 121/268 [00:26<00:30,  4.84it/s]
03/27 08:05:35 PM ***** Running evaluation *****
03/27 08:05:35 PM   Epoch = 28 iter 7599 step
03/27 08:05:35 PM   Num examples = 1043
03/27 08:05:35 PM   Batch size = 32
03/27 08:05:35 PM ***** Eval results *****
03/27 08:05:35 PM   att_loss = 5.553329929103696
03/27 08:05:35 PM   cls_loss = 0.0
03/27 08:05:35 PM   global_step = 7599
03/27 08:05:35 PM   loss = 6.117459239029303
03/27 08:05:35 PM   rep_loss = 0.5641292968416601






Iteration:  65%|######4   | 173/268 [00:38<00:38,  2.45it/s]
03/27 08:05:46 PM ***** Running evaluation *****
03/27 08:05:46 PM   Epoch = 28 iter 7649 step
03/27 08:05:46 PM   Num examples = 1043
03/27 08:05:46 PM   Batch size = 32
03/27 08:05:46 PM ***** Eval results *****
03/27 08:05:46 PM   att_loss = 5.558109969762019
03/27 08:05:46 PM   cls_loss = 0.0
03/27 08:05:46 PM   global_step = 7649
03/27 08:05:46 PM   loss = 6.122328953935921
03/27 08:05:46 PM   rep_loss = 0.5642189635017704





Iteration:  82%|########2 | 221/268 [00:48<00:09,  4.85it/s]
03/27 08:05:57 PM ***** Running evaluation *****
03/27 08:05:57 PM   Epoch = 28 iter 7699 step
03/27 08:05:57 PM   Num examples = 1043
03/27 08:05:57 PM   Batch size = 32
03/27 08:05:57 PM ***** Eval results *****
03/27 08:05:57 PM   att_loss = 5.543605639795551
03/27 08:05:57 PM   cls_loss = 0.0
03/27 08:05:57 PM   global_step = 7699
03/27 08:05:57 PM   loss = 6.106685437429111
03/27 08:05:57 PM   rep_loss = 0.5630797815964361




Epoch:  97%|█████████▋| 29/30 [28:21<00:58, 58.54s/it]4it/s]

Iteration:   2%|2         | 6/268 [00:01<01:53,  2.30it/s]
03/27 08:06:08 PM ***** Running evaluation *****
03/27 08:06:08 PM   Epoch = 29 iter 7749 step
03/27 08:06:08 PM   Num examples = 1043
03/27 08:06:08 PM   Batch size = 32
03/27 08:06:08 PM ***** Eval results *****
03/27 08:06:08 PM   att_loss = 5.461478392283122
03/27 08:06:08 PM   cls_loss = 0.0
03/27 08:06:08 PM   global_step = 7749
03/27 08:06:08 PM   loss = 6.017271916071574
03/27 08:06:08 PM   rep_loss = 0.5557936032613119





Iteration:  21%|##        | 55/268 [00:12<00:43,  4.85it/s]
03/27 08:06:19 PM ***** Running evaluation *****
03/27 08:06:19 PM   Epoch = 29 iter 7799 step
03/27 08:06:19 PM   Num examples = 1043
03/27 08:06:19 PM   Batch size = 32
03/27 08:06:19 PM ***** Eval results *****
03/27 08:06:19 PM   att_loss = 5.459401897021702
03/27 08:06:19 PM   cls_loss = 0.0
03/27 08:06:19 PM   global_step = 7799
03/27 08:06:19 PM   loss = 6.017682586397443
03/27 08:06:19 PM   rep_loss = 0.5582807223711695






Iteration:  40%|###9      | 107/268 [00:24<00:55,  2.89it/s]
03/27 08:06:30 PM ***** Running evaluation *****
03/27 08:06:30 PM   Epoch = 29 iter 7849 step
03/27 08:06:30 PM   Num examples = 1043
03/27 08:06:30 PM   Batch size = 32
03/27 08:06:30 PM ***** Eval results *****
03/27 08:06:30 PM   att_loss = 5.517193155468635
03/27 08:06:30 PM   cls_loss = 0.0
03/27 08:06:30 PM   global_step = 7849
03/27 08:06:30 PM   loss = 6.077497369838211
03/27 08:06:30 PM   rep_loss = 0.5603042391111266





Iteration:  58%|#####7    | 155/268 [00:33<00:23,  4.86it/s]
03/27 08:06:41 PM ***** Running evaluation *****
03/27 08:06:41 PM   Epoch = 29 iter 7899 step
03/27 08:06:41 PM   Num examples = 1043
03/27 08:06:41 PM   Batch size = 32
03/27 08:06:41 PM ***** Eval results *****
03/27 08:06:41 PM   att_loss = 5.528970397435701
03/27 08:06:41 PM   cls_loss = 0.0
03/27 08:06:41 PM   global_step = 7899
03/27 08:06:41 PM   loss = 6.089908914688306
03/27 08:06:41 PM   rep_loss = 0.5609385382670623






Iteration:  77%|#######7  | 207/268 [00:46<00:20,  2.92it/s]
03/27 08:06:52 PM ***** Running evaluation *****
03/27 08:06:52 PM   Epoch = 29 iter 7949 step
03/27 08:06:52 PM   Num examples = 1043
03/27 08:06:52 PM   Batch size = 32
03/27 08:06:52 PM ***** Eval results *****
03/27 08:06:52 PM   att_loss = 5.527922350226096
03/27 08:06:52 PM   cls_loss = 0.0
03/27 08:06:52 PM   global_step = 7949
03/27 08:06:52 PM   loss = 6.089573394905016
03/27 08:06:52 PM   rep_loss = 0.561651064932925





Iteration:  94%|#########4| 253/268 [00:55<00:03,  4.84it/s]
03/27 08:07:03 PM ***** Running evaluation *****
03/27 08:07:03 PM   Epoch = 29 iter 7999 step
03/27 08:07:03 PM   Num examples = 1043
03/27 08:07:03 PM   Batch size = 32
03/27 08:07:03 PM ***** Eval results *****
03/27 08:07:03 PM   att_loss = 5.525388916954398
03/27 08:07:03 PM   cls_loss = 0.0
03/27 08:07:03 PM   global_step = 7999
03/27 08:07:03 PM   loss = 6.086659859865904
03/27 08:07:03 PM   rep_loss = 0.5612709496635944


Epoch: 100%|██████████| 30/30 [29:20<00:00, 58.69s/it]7it/s]