03/28 12:09:00 AM device: cuda n_gpu: 1
03/28 12:09:00 AM Writing example 0 of 8551
03/28 12:09:00 AM *** Example ***
03/28 12:09:00 AM guid: train-0
03/28 12:09:00 AM tokens: [CLS] our friends won ' t buy this analysis , let alone the next one we propose . [SEP]
03/28 12:09:00 AM input_ids: 101 2256 2814 2180 1005 1056 4965 2023 4106 1010 2292 2894 1996 2279 2028 2057 16599 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/28 12:09:00 AM input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/28 12:09:00 AM segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/28 12:09:00 AM label: 1
03/28 12:09:00 AM label_id: 1
03/28 12:09:01 AM Writing example 0 of 1043
03/28 12:09:01 AM *** Example ***
03/28 12:09:01 AM guid: dev-0
03/28 12:09:01 AM tokens: [CLS] the sailors rode the breeze clear of the rocks . [SEP]
03/28 12:09:01 AM input_ids: 101 1996 11279 8469 1996 9478 3154 1997 1996 5749 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/28 12:09:01 AM input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/28 12:09:01 AM segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/28 12:09:01 AM label: 1
03/28 12:09:01 AM label_id: 1
03/28 12:09:01 AM loading archive file /w/331/adeemj/csc2516_proj/models/CoLA/models--textattack--bert-base-uncased-CoLA/snapshots/5fed03dd6bc5f0b40e86cb04cd1a16eb404ba391/
03/28 12:09:01 AM Model config {
  "architectures": [
    "BertForSequenceClassification"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "cola",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pre_trained": "",
  "training": "",
  "type_vocab_size": 2,
  "vocab_size": 30522
}
03/28 12:09:03 AM Loading model /w/331/adeemj/csc2516_proj/models/CoLA/models--textattack--bert-base-uncased-CoLA/snapshots/5fed03dd6bc5f0b40e86cb04cd1a16eb404ba391/pytorch_model.bin
03/28 12:09:03 AM loading model...
03/28 12:09:03 AM done!
03/28 12:09:03 AM Weights of TinyBertForSequenceClassification not initialized from pretrained model: ['fit_dense.weight', 'fit_dense.bias']
03/28 12:09:03 AM loading archive file /w/331/adeemj/csc2516_proj/models/CoLA/KL_ATTN_SWEEP_BATCHMEAN/TempTinyBERT_CoLA_4L_312D_kl_weight0.01
03/28 12:09:03 AM Model config {
  "attention_probs_dropout_prob": 0.1,
  "cell": {},
  "emb_size": 312,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 312,
  "initializer_range": 0.02,
  "intermediate_size": 1200,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 4,
  "pre_trained": "",
  "structure": [],
  "training": "",
  "type_vocab_size": 2,
  "vocab_size": 30522
}
03/28 12:09:03 AM Loading model /w/331/adeemj/csc2516_proj/models/CoLA/KL_ATTN_SWEEP_BATCHMEAN/TempTinyBERT_CoLA_4L_312D_kl_weight0.01/pytorch_model.bin
03/28 12:09:03 AM loading model...
03/28 12:09:03 AM done!
03/28 12:09:03 AM ***** Running training *****
03/28 12:09:03 AM   Num examples = 8551
03/28 12:09:03 AM   Batch size = 16
03/28 12:09:03 AM   Num steps = 1602
03/28 12:09:03 AM n: bert.embeddings.word_embeddings.weight
03/28 12:09:03 AM n: bert.embeddings.position_embeddings.weight
03/28 12:09:03 AM n: bert.embeddings.token_type_embeddings.weight
03/28 12:09:03 AM n: bert.embeddings.LayerNorm.weight
03/28 12:09:03 AM n: bert.embeddings.LayerNorm.bias
03/28 12:09:03 AM n: bert.encoder.layer.0.attention.self.query.weight
03/28 12:09:03 AM n: bert.encoder.layer.0.attention.self.query.bias
03/28 12:09:03 AM n: bert.encoder.layer.0.attention.self.key.weight
03/28 12:09:03 AM n: bert.encoder.layer.0.attention.self.key.bias
03/28 12:09:03 AM n: bert.encoder.layer.0.attention.self.value.weight
03/28 12:09:03 AM n: bert.encoder.layer.0.attention.self.value.bias
03/28 12:09:03 AM n: bert.encoder.layer.0.attention.output.dense.weight
03/28 12:09:03 AM n: bert.encoder.layer.0.attention.output.dense.bias
03/28 12:09:03 AM n: bert.encoder.layer.0.attention.output.LayerNorm.weight
03/28 12:09:03 AM n: bert.encoder.layer.0.attention.output.LayerNorm.bias
03/28 12:09:03 AM n: bert.encoder.layer.0.intermediate.dense.weight
03/28 12:09:03 AM n: bert.encoder.layer.0.intermediate.dense.bias
03/28 12:09:03 AM n: bert.encoder.layer.0.output.dense.weight
03/28 12:09:03 AM n: bert.encoder.layer.0.output.dense.bias
03/28 12:09:03 AM n: bert.encoder.layer.0.output.LayerNorm.weight
03/28 12:09:03 AM n: bert.encoder.layer.0.output.LayerNorm.bias
03/28 12:09:03 AM n: bert.encoder.layer.1.attention.self.query.weight
03/28 12:09:03 AM n: bert.encoder.layer.1.attention.self.query.bias
03/28 12:09:03 AM n: bert.encoder.layer.1.attention.self.key.weight
03/28 12:09:03 AM n: bert.encoder.layer.1.attention.self.key.bias
03/28 12:09:03 AM n: bert.encoder.layer.1.attention.self.value.weight
03/28 12:09:03 AM n: bert.encoder.layer.1.attention.self.value.bias
03/28 12:09:03 AM n: bert.encoder.layer.1.attention.output.dense.weight
03/28 12:09:03 AM n: bert.encoder.layer.1.attention.output.dense.bias
03/28 12:09:03 AM n: bert.encoder.layer.1.attention.output.LayerNorm.weight
03/28 12:09:03 AM n: bert.encoder.layer.1.attention.output.LayerNorm.bias
03/28 12:09:03 AM n: bert.encoder.layer.1.intermediate.dense.weight
03/28 12:09:03 AM n: bert.encoder.layer.1.intermediate.dense.bias
03/28 12:09:03 AM n: bert.encoder.layer.1.output.dense.weight
03/28 12:09:03 AM n: bert.encoder.layer.1.output.dense.bias
03/28 12:09:03 AM n: bert.encoder.layer.1.output.LayerNorm.weight
03/28 12:09:03 AM n: bert.encoder.layer.1.output.LayerNorm.bias
03/28 12:09:03 AM n: bert.encoder.layer.2.attention.self.query.weight
03/28 12:09:03 AM n: bert.encoder.layer.2.attention.self.query.bias
03/28 12:09:03 AM n: bert.encoder.layer.2.attention.self.key.weight
03/28 12:09:03 AM n: bert.encoder.layer.2.attention.self.key.bias
03/28 12:09:03 AM n: bert.encoder.layer.2.attention.self.value.weight
03/28 12:09:03 AM n: bert.encoder.layer.2.attention.self.value.bias
03/28 12:09:03 AM n: bert.encoder.layer.2.attention.output.dense.weight
03/28 12:09:03 AM n: bert.encoder.layer.2.attention.output.dense.bias
03/28 12:09:03 AM n: bert.encoder.layer.2.attention.output.LayerNorm.weight
03/28 12:09:03 AM n: bert.encoder.layer.2.attention.output.LayerNorm.bias
03/28 12:09:03 AM n: bert.encoder.layer.2.intermediate.dense.weight
03/28 12:09:03 AM n: bert.encoder.layer.2.intermediate.dense.bias
03/28 12:09:03 AM n: bert.encoder.layer.2.output.dense.weight
03/28 12:09:03 AM n: bert.encoder.layer.2.output.dense.bias
03/28 12:09:03 AM n: bert.encoder.layer.2.output.LayerNorm.weight
03/28 12:09:03 AM n: bert.encoder.layer.2.output.LayerNorm.bias
03/28 12:09:03 AM n: bert.encoder.layer.3.attention.self.query.weight
03/28 12:09:03 AM n: bert.encoder.layer.3.attention.self.query.bias
03/28 12:09:03 AM n: bert.encoder.layer.3.attention.self.key.weight
03/28 12:09:03 AM n: bert.encoder.layer.3.attention.self.key.bias
03/28 12:09:03 AM n: bert.encoder.layer.3.attention.self.value.weight
03/28 12:09:03 AM n: bert.encoder.layer.3.attention.self.value.bias
03/28 12:09:03 AM n: bert.encoder.layer.3.attention.output.dense.weight
03/28 12:09:03 AM n: bert.encoder.layer.3.attention.output.dense.bias
03/28 12:09:03 AM n: bert.encoder.layer.3.attention.output.LayerNorm.weight
03/28 12:09:03 AM n: bert.encoder.layer.3.attention.output.LayerNorm.bias
03/28 12:09:03 AM n: bert.encoder.layer.3.intermediate.dense.weight
03/28 12:09:03 AM n: bert.encoder.layer.3.intermediate.dense.bias
03/28 12:09:03 AM n: bert.encoder.layer.3.output.dense.weight
03/28 12:09:03 AM n: bert.encoder.layer.3.output.dense.bias
03/28 12:09:03 AM n: bert.encoder.layer.3.output.LayerNorm.weight
03/28 12:09:03 AM n: bert.encoder.layer.3.output.LayerNorm.bias
03/28 12:09:03 AM n: bert.pooler.dense.weight
03/28 12:09:03 AM n: bert.pooler.dense.bias
03/28 12:09:03 AM n: classifier.weight
03/28 12:09:03 AM n: classifier.bias
03/28 12:09:03 AM n: fit_dense.weight
03/28 12:09:03 AM n: fit_dense.bias
03/28 12:09:03 AM Total parameters: 14591258
Epoch:   0%|          | 0/3 [00:00<?, ?it/s]



Iteration:   9%|8         | 46/535 [00:07<01:18,  6.24it/s]
03/28 12:09:11 AM ***** Running evaluation *****
03/28 12:09:11 AM   Epoch = 0 iter 49 step
03/28 12:09:11 AM   Num examples = 1043
Iteration:   9%|8         | 48/535 [00:07<01:17,  6.25it/s]
Iteration:  10%|9         | 51/535 [00:09<02:50,  2.85it/s]
03/28 12:09:12 AM ***** Eval results *****
03/28 12:09:12 AM   acc = 0.7123681687440077
03/28 12:09:12 AM   att_loss = 0.0
03/28 12:09:12 AM   cls_loss = 0.3283280663344325
03/28 12:09:12 AM   eval_loss = 0.59939587838722
03/28 12:09:12 AM   global_step = 49
03/28 12:09:12 AM   loss = 0.3283280663344325
03/28 12:09:12 AM   mcc = 0.27740658764302706
03/28 12:09:12 AM   rep_loss = 0.0



Iteration:  18%|#8        | 98/535 [00:17<01:09,  6.24it/s]
Evaluating:  36%|███▋      | 12/33 [00:00<00:00, 54.49it/s]
03/28 12:09:20 AM ***** Running evaluation *****
03/28 12:09:20 AM   Epoch = 0 iter 99 step
03/28 12:09:20 AM   Num examples = 1043
03/28 12:09:20 AM   Batch size = 32
03/28 12:09:21 AM ***** Eval results *****
03/28 12:09:21 AM   acc = 0.7046979865771812
03/28 12:09:21 AM   att_loss = 0.0
03/28 12:09:21 AM   cls_loss = 0.31092522752405416
03/28 12:09:21 AM   eval_loss = 0.5854144096374512
03/28 12:09:21 AM   global_step = 99
03/28 12:09:21 AM   loss = 0.31092522752405416
03/28 12:09:21 AM   mcc = 0.3237953631930207
03/28 12:09:21 AM   rep_loss = 0.0




Iteration:  28%|##7       | 148/535 [00:26<01:02,  6.23it/s]
Evaluating:  91%|█████████ | 30/33 [00:00<00:00, 54.26it/s]
03/28 12:09:30 AM ***** Running evaluation *****
03/28 12:09:30 AM   Epoch = 0 iter 149 step
03/28 12:09:30 AM   Num examples = 1043
03/28 12:09:30 AM   Batch size = 32
03/28 12:09:30 AM ***** Eval results *****
03/28 12:09:30 AM   acc = 0.7238734419942474
03/28 12:09:30 AM   att_loss = 0.0
03/28 12:09:30 AM   cls_loss = 0.3030981437471889
03/28 12:09:30 AM   eval_loss = 0.5736978315945828
03/28 12:09:30 AM   global_step = 149
03/28 12:09:30 AM   loss = 0.3030981437471889
03/28 12:09:30 AM   mcc = 0.32422602944663587
03/28 12:09:30 AM   rep_loss = 0.0




Iteration:  37%|###6      | 196/535 [00:35<00:54,  6.23it/s]
03/28 12:09:39 AM ***** Running evaluation *****
03/28 12:09:39 AM   Epoch = 0 iter 199 step
03/28 12:09:39 AM   Num examples = 1043
Iteration:  37%|###7      | 198/535 [00:35<00:54,  6.22it/s]
Iteration:  38%|###8      | 205/535 [00:37<01:00,  5.48it/s]
03/28 12:09:40 AM ***** Eval results *****
03/28 12:09:40 AM   acc = 0.7305848513902206
03/28 12:09:40 AM   att_loss = 0.0
03/28 12:09:40 AM   cls_loss = 0.29842364930327814
03/28 12:09:40 AM   eval_loss = 0.5557437882278905
03/28 12:09:40 AM   global_step = 199
03/28 12:09:40 AM   loss = 0.29842364930327814
03/28 12:09:40 AM   mcc = 0.28696235374396895



Iteration:  46%|####6     | 248/535 [00:44<00:46,  6.16it/s]
Iteration:  47%|####6     | 251/535 [00:45<01:11,  3.96it/s]
03/28 12:09:48 AM ***** Running evaluation *****
03/28 12:09:48 AM   Epoch = 0 iter 249 step
03/28 12:09:48 AM   Num examples = 1043
03/28 12:09:48 AM   Batch size = 32
03/28 12:09:48 AM ***** Eval results *****
03/28 12:09:48 AM   acc = 0.7344199424736337
03/28 12:09:48 AM   att_loss = 0.0
03/28 12:09:48 AM   cls_loss = 0.2946288312774107
03/28 12:09:48 AM   eval_loss = 0.5637156439549995
03/28 12:09:48 AM   global_step = 249
03/28 12:09:48 AM   loss = 0.2946288312774107
03/28 12:09:48 AM   mcc = 0.2940905497972125



Iteration:  56%|#####5    | 298/535 [00:53<00:38,  6.20it/s]
Evaluating:  55%|█████▍    | 18/33 [00:00<00:00, 54.36it/s]
03/28 12:09:56 AM ***** Running evaluation *****
03/28 12:09:56 AM   Epoch = 0 iter 299 step
03/28 12:09:56 AM   Num examples = 1043
03/28 12:09:56 AM   Batch size = 32
03/28 12:09:57 AM ***** Eval results *****
03/28 12:09:57 AM   acc = 0.7171620325982742
03/28 12:09:57 AM   att_loss = 0.0
03/28 12:09:57 AM   cls_loss = 0.29266029337178107
03/28 12:09:57 AM   eval_loss = 0.5612032178676489
03/28 12:09:57 AM   global_step = 299
03/28 12:09:57 AM   loss = 0.29266029337178107
03/28 12:09:57 AM   mcc = 0.2852679092106396




Iteration:  65%|######4   | 347/535 [01:01<00:30,  6.22it/s]
03/28 12:10:05 AM ***** Running evaluation *****
03/28 12:10:05 AM   Epoch = 0 iter 349 step
03/28 12:10:05 AM   Num examples = 1043
Iteration:  65%|######5   | 348/535 [01:01<00:30,  6.22it/s]
Iteration:  66%|######6   | 355/535 [01:03<00:32,  5.48it/s]
03/28 12:10:06 AM ***** Eval results *****
03/28 12:10:06 AM   acc = 0.7219558964525408
03/28 12:10:06 AM   att_loss = 0.0
03/28 12:10:06 AM   cls_loss = 0.29105806196999756
03/28 12:10:06 AM   eval_loss = 0.5500552166591991
03/28 12:10:06 AM   global_step = 349
03/28 12:10:06 AM   loss = 0.29105806196999756
03/28 12:10:06 AM   mcc = 0.2683934054786649



Iteration:  74%|#######4  | 398/535 [01:10<00:21,  6.23it/s]
Iteration:  75%|#######4  | 401/535 [01:11<00:33,  3.99it/s]
03/28 12:10:14 AM ***** Running evaluation *****
03/28 12:10:14 AM   Epoch = 0 iter 399 step
03/28 12:10:14 AM   Num examples = 1043
03/28 12:10:14 AM   Batch size = 32
03/28 12:10:14 AM ***** Eval results *****
03/28 12:10:14 AM   acc = 0.7296260786193672
03/28 12:10:14 AM   att_loss = 0.0
03/28 12:10:14 AM   cls_loss = 0.2900835150913487
03/28 12:10:14 AM   eval_loss = 0.5486904825225021
03/28 12:10:14 AM   global_step = 399
03/28 12:10:14 AM   loss = 0.2900835150913487
03/28 12:10:14 AM   mcc = 0.287324023093052



Iteration:  84%|########3 | 448/535 [01:19<00:14,  6.21it/s]
Evaluating:  55%|█████▍    | 18/33 [00:00<00:00, 54.23it/s]
03/28 12:10:22 AM ***** Running evaluation *****
03/28 12:10:22 AM   Epoch = 0 iter 449 step
03/28 12:10:22 AM   Num examples = 1043
03/28 12:10:22 AM   Batch size = 32
03/28 12:10:23 AM ***** Eval results *****
03/28 12:10:23 AM   acc = 0.7277085330776606
03/28 12:10:23 AM   att_loss = 0.0
03/28 12:10:23 AM   cls_loss = 0.28854837771380665
03/28 12:10:23 AM   eval_loss = 0.5578452294523065
03/28 12:10:23 AM   global_step = 449
03/28 12:10:23 AM   loss = 0.28854837771380665
03/28 12:10:23 AM   mcc = 0.320997827186018




Iteration:  93%|#########2| 497/535 [01:27<00:06,  6.20it/s]
03/28 12:10:31 AM ***** Running evaluation *****
03/28 12:10:31 AM   Epoch = 0 iter 499 step
03/28 12:10:31 AM   Num examples = 1043
Iteration:  93%|#########3| 498/535 [01:27<00:05,  6.21it/s]
Iteration:  94%|#########3| 501/535 [01:29<00:12,  2.82it/s]
03/28 12:10:32 AM ***** Eval results *****
03/28 12:10:32 AM   acc = 0.7430488974113135
03/28 12:10:32 AM   att_loss = 0.0
03/28 12:10:32 AM   cls_loss = 0.2871336294618064
03/28 12:10:32 AM   eval_loss = 0.5510263226249001
03/28 12:10:32 AM   global_step = 499
03/28 12:10:32 AM   loss = 0.2871336294618064
03/28 12:10:32 AM   mcc = 0.3270645042567984
03/28 12:10:32 AM   rep_loss = 0.0


Epoch:  33%|███▎      | 1/3 [01:34<03:09, 94.87s/it].19it/s]
Iteration:   3%|2         | 14/535 [00:02<01:24,  6.19it/s]
Evaluating:  55%|█████▍    | 18/33 [00:00<00:00, 54.20it/s]
03/28 12:10:40 AM ***** Running evaluation *****
03/28 12:10:40 AM   Epoch = 1 iter 549 step
03/28 12:10:40 AM   Num examples = 1043
03/28 12:10:40 AM   Batch size = 32
03/28 12:10:41 AM ***** Eval results *****
03/28 12:10:41 AM   acc = 0.7344199424736337
03/28 12:10:41 AM   att_loss = 0.0
03/28 12:10:41 AM   cls_loss = 0.2716089516878128
03/28 12:10:41 AM   eval_loss = 0.5500055361877788
03/28 12:10:41 AM   global_step = 549
03/28 12:10:41 AM   loss = 0.2716089516878128
03/28 12:10:41 AM   mcc = 0.3214888858177521




Iteration:  12%|#1        | 63/535 [00:10<01:15,  6.22it/s]
03/28 12:10:49 AM ***** Running evaluation *****
03/28 12:10:49 AM   Epoch = 1 iter 599 step
03/28 12:10:49 AM   Num examples = 1043
Iteration:  12%|#1        | 64/535 [00:10<01:15,  6.20it/s]
Iteration:  13%|#3        | 72/535 [00:12<01:21,  5.68it/s]
03/28 12:10:50 AM ***** Eval results *****
03/28 12:10:50 AM   acc = 0.7344199424736337
03/28 12:10:50 AM   att_loss = 0.0
03/28 12:10:50 AM   cls_loss = 0.2765833685031304
03/28 12:10:50 AM   eval_loss = 0.5430646845788667
03/28 12:10:50 AM   global_step = 599
03/28 12:10:50 AM   loss = 0.2765833685031304
03/28 12:10:50 AM   mcc = 0.31087774676686925



Iteration:  21%|##1       | 114/535 [00:19<01:08,  6.18it/s]
Iteration:  22%|##2       | 118/535 [00:20<01:33,  4.47it/s]
03/28 12:10:58 AM ***** Running evaluation *****
03/28 12:10:58 AM   Epoch = 1 iter 649 step
03/28 12:10:58 AM   Num examples = 1043
03/28 12:10:58 AM   Batch size = 32
03/28 12:10:58 AM ***** Eval results *****
03/28 12:10:58 AM   acc = 0.7334611697027804
03/28 12:10:58 AM   att_loss = 0.0
03/28 12:10:58 AM   cls_loss = 0.27576247790585395
03/28 12:10:58 AM   eval_loss = 0.5451278948422634
03/28 12:10:58 AM   global_step = 649
03/28 12:10:58 AM   loss = 0.27576247790585395
03/28 12:10:58 AM   mcc = 0.3225892878730812



Iteration:  31%|###       | 164/535 [00:28<00:59,  6.20it/s]
Evaluating:  55%|█████▍    | 18/33 [00:00<00:00, 54.23it/s]
03/28 12:11:06 AM ***** Running evaluation *****
03/28 12:11:06 AM   Epoch = 1 iter 699 step
03/28 12:11:06 AM   Num examples = 1043
03/28 12:11:06 AM   Batch size = 32
03/28 12:11:07 AM ***** Eval results *****
03/28 12:11:07 AM   acc = 0.7372962607861937
03/28 12:11:07 AM   att_loss = 0.0
03/28 12:11:07 AM   cls_loss = 0.27461838090058527
03/28 12:11:07 AM   eval_loss = 0.5426828527089321
03/28 12:11:07 AM   global_step = 699
03/28 12:11:07 AM   loss = 0.27461838090058527
03/28 12:11:07 AM   mcc = 0.3195441399431679




Iteration:  40%|###9      | 213/535 [00:36<00:51,  6.20it/s]
03/28 12:11:15 AM ***** Running evaluation *****
03/28 12:11:15 AM   Epoch = 1 iter 749 step
03/28 12:11:15 AM   Num examples = 1043
Iteration:  40%|####      | 214/535 [00:36<00:51,  6.19it/s]
Iteration:  41%|####      | 218/535 [00:38<01:33,  3.40it/s]
03/28 12:11:16 AM ***** Eval results *****
03/28 12:11:16 AM   acc = 0.7372962607861937
03/28 12:11:16 AM   att_loss = 0.0
03/28 12:11:16 AM   cls_loss = 0.274618001316869
03/28 12:11:16 AM   eval_loss = 0.5490935417738828
03/28 12:11:16 AM   global_step = 749
03/28 12:11:16 AM   loss = 0.274618001316869
03/28 12:11:16 AM   mcc = 0.32743517887814166
03/28 12:11:16 AM   rep_loss = 0.0



Iteration:  49%|####9     | 264/535 [00:46<00:43,  6.20it/s]
Evaluating:  73%|███████▎  | 24/33 [00:00<00:00, 54.21it/s]
03/28 12:11:25 AM ***** Running evaluation *****
03/28 12:11:25 AM   Epoch = 1 iter 799 step
03/28 12:11:25 AM   Num examples = 1043
03/28 12:11:25 AM   Batch size = 32
03/28 12:11:25 AM ***** Eval results *****
03/28 12:11:25 AM   acc = 0.7315436241610739
03/28 12:11:25 AM   att_loss = 0.0
03/28 12:11:25 AM   cls_loss = 0.2738011497371602
03/28 12:11:25 AM   eval_loss = 0.5542273033748973
03/28 12:11:25 AM   global_step = 799
03/28 12:11:25 AM   loss = 0.2738011497371602
03/28 12:11:25 AM   mcc = 0.3364667090764656
03/28 12:11:25 AM   rep_loss = 0.0




Iteration:  59%|#####8    | 314/535 [00:55<00:35,  6.19it/s]
Evaluating:  91%|█████████ | 30/33 [00:00<00:00, 53.78it/s]
03/28 12:11:34 AM ***** Running evaluation *****
03/28 12:11:34 AM   Epoch = 1 iter 849 step
03/28 12:11:34 AM   Num examples = 1043
03/28 12:11:34 AM   Batch size = 32
03/28 12:11:34 AM ***** Eval results *****
03/28 12:11:34 AM   acc = 0.7430488974113135
03/28 12:11:34 AM   att_loss = 0.0
03/28 12:11:34 AM   cls_loss = 0.2740212007174416
03/28 12:11:34 AM   eval_loss = 0.5429370918057181
03/28 12:11:34 AM   global_step = 849
03/28 12:11:34 AM   loss = 0.2740212007174416
03/28 12:11:34 AM   mcc = 0.3380063289865065
03/28 12:11:34 AM   rep_loss = 0.0




Iteration:  68%|######7   | 363/535 [01:04<00:27,  6.23it/s]
03/28 12:11:43 AM ***** Running evaluation *****
03/28 12:11:43 AM   Epoch = 1 iter 899 step
03/28 12:11:43 AM   Num examples = 1043
Iteration:  68%|######8   | 364/535 [01:05<00:27,  6.22it/s]
Iteration:  70%|######9   | 372/535 [01:06<00:28,  5.67it/s]
03/28 12:11:44 AM ***** Eval results *****
03/28 12:11:44 AM   acc = 0.7305848513902206
03/28 12:11:44 AM   att_loss = 0.0
03/28 12:11:44 AM   cls_loss = 0.27381703400448576
03/28 12:11:44 AM   eval_loss = 0.5531656868530043
03/28 12:11:44 AM   global_step = 899
03/28 12:11:44 AM   loss = 0.27381703400448576
03/28 12:11:44 AM   mcc = 0.32605098190985565



Iteration:  77%|#######7  | 414/535 [01:13<00:19,  6.22it/s]
Iteration:  78%|#######8  | 418/535 [01:14<00:26,  4.47it/s]
03/28 12:11:52 AM ***** Running evaluation *****
03/28 12:11:52 AM   Epoch = 1 iter 949 step
03/28 12:11:52 AM   Num examples = 1043
03/28 12:11:52 AM   Batch size = 32
03/28 12:11:53 AM ***** Eval results *****
03/28 12:11:53 AM   acc = 0.7372962607861937
03/28 12:11:53 AM   att_loss = 0.0
03/28 12:11:53 AM   cls_loss = 0.27364335850060706
03/28 12:11:53 AM   eval_loss = 0.5432972311973572
03/28 12:11:53 AM   global_step = 949
03/28 12:11:53 AM   loss = 0.27364335850060706
03/28 12:11:53 AM   mcc = 0.3259325330443582



Iteration:  87%|########6 | 464/535 [01:22<00:11,  6.19it/s]
Evaluating:  73%|███████▎  | 24/33 [00:00<00:00, 54.05it/s]
03/28 12:12:01 AM ***** Running evaluation *****
03/28 12:12:01 AM   Epoch = 1 iter 999 step
03/28 12:12:01 AM   Num examples = 1043
03/28 12:12:01 AM   Batch size = 32
03/28 12:12:01 AM ***** Eval results *****
03/28 12:12:01 AM   acc = 0.7440076701821668
03/28 12:12:01 AM   att_loss = 0.0
03/28 12:12:01 AM   cls_loss = 0.2731752650712126
03/28 12:12:01 AM   eval_loss = 0.5413061940308773
03/28 12:12:01 AM   global_step = 999
03/28 12:12:01 AM   loss = 0.2731752650712126
03/28 12:12:01 AM   mcc = 0.3306219515641091




Iteration:  96%|#########5| 513/535 [01:30<00:03,  6.19it/s]
03/28 12:12:09 AM ***** Running evaluation *****
03/28 12:12:09 AM   Epoch = 1 iter 1049 step
03/28 12:12:09 AM   Num examples = 1043
Iteration:  96%|#########6| 514/535 [01:31<00:03,  6.18it/s]
Iteration:  98%|#########7| 522/535 [01:32<00:02,  5.66it/s]
03/28 12:12:10 AM ***** Eval results *****
03/28 12:12:10 AM   acc = 0.738255033557047
03/28 12:12:10 AM   att_loss = 0.0
03/28 12:12:10 AM   cls_loss = 0.27321593871394406
03/28 12:12:10 AM   eval_loss = 0.5413706736131148
03/28 12:12:10 AM   global_step = 1049
03/28 12:12:10 AM   loss = 0.27321593871394406
03/28 12:12:10 AM   mcc = 0.32467991850218353
Epoch:  67%|██████▋   | 2/3 [03:09<01:34, 94.89s/it].22it/s]


Iteration:   6%|5         | 30/535 [00:04<01:21,  6.18it/s]
Iteration:   6%|6         | 34/535 [00:06<01:52,  4.44it/s]
03/28 12:12:18 AM ***** Running evaluation *****
03/28 12:12:18 AM   Epoch = 2 iter 1099 step
03/28 12:12:18 AM   Num examples = 1043
03/28 12:12:18 AM   Batch size = 32
03/28 12:12:19 AM ***** Eval results *****
03/28 12:12:19 AM   acc = 0.7305848513902206
03/28 12:12:19 AM   att_loss = 0.0
03/28 12:12:19 AM   cls_loss = 0.2685939659995417
03/28 12:12:19 AM   eval_loss = 0.5417754930077177
03/28 12:12:19 AM   global_step = 1099
03/28 12:12:19 AM   loss = 0.2685939659995417
03/28 12:12:19 AM   mcc = 0.31185098672151873



Iteration:  15%|#4        | 80/535 [00:13<01:13,  6.21it/s]
Evaluating:  73%|███████▎  | 24/33 [00:00<00:00, 53.76it/s]
03/28 12:12:27 AM ***** Running evaluation *****
03/28 12:12:27 AM   Epoch = 2 iter 1149 step
03/28 12:12:27 AM   Num examples = 1043
03/28 12:12:27 AM   Batch size = 32
03/28 12:12:27 AM ***** Eval results *****
03/28 12:12:27 AM   acc = 0.7401725790987536
03/28 12:12:27 AM   att_loss = 0.0
03/28 12:12:27 AM   cls_loss = 0.2715171111954583
03/28 12:12:27 AM   eval_loss = 0.5379424600890188
03/28 12:12:27 AM   global_step = 1149
03/28 12:12:27 AM   loss = 0.2715171111954583
03/28 12:12:27 AM   mcc = 0.32753989938135253




Iteration:  24%|##4       | 129/535 [00:22<01:05,  6.21it/s]
03/28 12:12:35 AM ***** Running evaluation *****
03/28 12:12:35 AM   Epoch = 2 iter 1199 step
03/28 12:12:35 AM   Num examples = 1043
Iteration:  24%|##4       | 130/535 [00:22<01:05,  6.20it/s]
Iteration:  26%|##5       | 138/535 [00:24<01:09,  5.70it/s]
03/28 12:12:36 AM ***** Eval results *****
03/28 12:12:36 AM   acc = 0.7401725790987536
03/28 12:12:36 AM   att_loss = 0.0
03/28 12:12:36 AM   cls_loss = 0.27032440184181883
03/28 12:12:36 AM   eval_loss = 0.5379777433294238
03/28 12:12:36 AM   global_step = 1199
03/28 12:12:36 AM   loss = 0.27032440184181883
03/28 12:12:36 AM   mcc = 0.33796416926704326



Iteration:  34%|###3      | 180/535 [00:30<00:57,  6.19it/s]
Iteration:  34%|###4      | 184/535 [00:32<01:18,  4.46it/s]
03/28 12:12:44 AM ***** Running evaluation *****
03/28 12:12:44 AM   Epoch = 2 iter 1249 step
03/28 12:12:44 AM   Num examples = 1043
03/28 12:12:44 AM   Batch size = 32
03/28 12:12:45 AM ***** Eval results *****
03/28 12:12:45 AM   acc = 0.7363374880153404
03/28 12:12:45 AM   att_loss = 0.0
03/28 12:12:45 AM   cls_loss = 0.27106529004995333
03/28 12:12:45 AM   eval_loss = 0.537276872179725
03/28 12:12:45 AM   global_step = 1249
03/28 12:12:45 AM   loss = 0.27106529004995333
03/28 12:12:45 AM   mcc = 0.3244057129208282



Iteration:  43%|####2     | 230/535 [00:39<00:48,  6.24it/s]
Evaluating:  73%|███████▎  | 24/33 [00:00<00:00, 53.76it/s]
03/28 12:12:53 AM ***** Running evaluation *****
03/28 12:12:53 AM   Epoch = 2 iter 1299 step
03/28 12:12:53 AM   Num examples = 1043
03/28 12:12:53 AM   Batch size = 32
03/28 12:12:53 AM ***** Eval results *****
03/28 12:12:53 AM   acc = 0.738255033557047
03/28 12:12:53 AM   att_loss = 0.0
03/28 12:12:53 AM   cls_loss = 0.27078252288944277
03/28 12:12:53 AM   eval_loss = 0.5372213332942037
03/28 12:12:53 AM   global_step = 1299
03/28 12:12:53 AM   loss = 0.27078252288944277
03/28 12:12:53 AM   mcc = 0.3342982430724728




Iteration:  52%|#####2    | 280/535 [00:48<00:41,  6.20it/s]
03/28 12:13:01 AM ***** Running evaluation *****
03/28 12:13:01 AM   Epoch = 2 iter 1349 step
03/28 12:13:01 AM   Num examples = 1043
03/28 12:13:01 AM   Batch size = 32
Iteration:  53%|#####3    | 284/535 [00:50<01:13,  3.39it/s]
03/28 12:13:02 AM ***** Eval results *****
03/28 12:13:02 AM   acc = 0.7449664429530202
03/28 12:13:02 AM   att_loss = 0.0
03/28 12:13:02 AM   cls_loss = 0.2707341301695732
03/28 12:13:02 AM   eval_loss = 0.5376597435185404
03/28 12:13:02 AM   global_step = 1349
03/28 12:13:02 AM   loss = 0.2707341301695732
03/28 12:13:02 AM   mcc = 0.34114287267917587
03/28 12:13:02 AM   rep_loss = 0.0



Iteration:  62%|######1   | 330/535 [00:57<00:32,  6.22it/s]
Evaluating:  73%|███████▎  | 24/33 [00:00<00:00, 54.14it/s]
03/28 12:13:11 AM ***** Running evaluation *****
03/28 12:13:11 AM   Epoch = 2 iter 1399 step
03/28 12:13:11 AM   Num examples = 1043
03/28 12:13:11 AM   Batch size = 32
03/28 12:13:11 AM ***** Eval results *****
03/28 12:13:11 AM   acc = 0.7430488974113135
03/28 12:13:11 AM   att_loss = 0.0
03/28 12:13:11 AM   cls_loss = 0.27104338211235324
03/28 12:13:11 AM   eval_loss = 0.5376112000508741
03/28 12:13:11 AM   global_step = 1399
03/28 12:13:11 AM   loss = 0.27104338211235324
03/28 12:13:11 AM   mcc = 0.3392796829282613




Iteration:  71%|#######1  | 380/535 [01:06<00:25,  6.20it/s]
03/28 12:13:19 AM ***** Running evaluation *****
03/28 12:13:19 AM   Epoch = 2 iter 1449 step
03/28 12:13:19 AM   Num examples = 1043
03/28 12:13:19 AM   Batch size = 32
Iteration:  73%|#######2  | 388/535 [01:08<00:25,  5.67it/s]
03/28 12:13:20 AM ***** Eval results *****
03/28 12:13:20 AM   acc = 0.7420901246404602
03/28 12:13:20 AM   att_loss = 0.0
03/28 12:13:20 AM   cls_loss = 0.27060766799712743
03/28 12:13:20 AM   eval_loss = 0.5387037857012316
03/28 12:13:20 AM   global_step = 1449
03/28 12:13:20 AM   loss = 0.27060766799712743
03/28 12:13:20 AM   mcc = 0.33689855976359306



Iteration:  80%|########  | 430/535 [01:14<00:16,  6.20it/s]
Iteration:  81%|########1 | 434/535 [01:16<00:22,  4.45it/s]
03/28 12:13:28 AM ***** Running evaluation *****
03/28 12:13:28 AM   Epoch = 2 iter 1499 step
03/28 12:13:28 AM   Num examples = 1043
03/28 12:13:28 AM   Batch size = 32
03/28 12:13:29 AM ***** Eval results *****
03/28 12:13:29 AM   acc = 0.7392138063279002
03/28 12:13:29 AM   att_loss = 0.0
03/28 12:13:29 AM   cls_loss = 0.2705608833486132
03/28 12:13:29 AM   eval_loss = 0.538345832716335
03/28 12:13:29 AM   global_step = 1499
03/28 12:13:29 AM   loss = 0.2705608833486132
03/28 12:13:29 AM   mcc = 0.3327272758141264



Iteration:  90%|########9 | 480/535 [01:23<00:08,  6.18it/s]
Evaluating:  73%|███████▎  | 24/33 [00:00<00:00, 54.13it/s]
03/28 12:13:37 AM ***** Running evaluation *****
03/28 12:13:37 AM   Epoch = 2 iter 1549 step
03/28 12:13:37 AM   Num examples = 1043
03/28 12:13:37 AM   Batch size = 32
03/28 12:13:37 AM ***** Eval results *****
03/28 12:13:37 AM   acc = 0.738255033557047
03/28 12:13:37 AM   att_loss = 0.0
03/28 12:13:37 AM   cls_loss = 0.27041230711644504
03/28 12:13:37 AM   eval_loss = 0.5390039411458102
03/28 12:13:37 AM   global_step = 1549
03/28 12:13:37 AM   loss = 0.27041230711644504
03/28 12:13:37 AM   mcc = 0.3335166592636138




Iteration:  99%|#########9| 530/535 [01:32<00:00,  6.22it/s]
03/28 12:13:45 AM ***** Running evaluation *****
03/28 12:13:45 AM   Epoch = 2 iter 1599 step
03/28 12:13:45 AM   Num examples = 1043
Iteration: 100%|##########| 535/535 [01:33<00:00,  5.72it/s]
Epoch: 100%|██████████| 3/3 [04:43<00:00, 94.45s/it].44it/s]
03/28 12:13:46 AM ***** Eval results *****
03/28 12:13:46 AM   acc = 0.7420901246404602
03/28 12:13:46 AM   att_loss = 0.0
03/28 12:13:46 AM   cls_loss = 0.27021937930988055
03/28 12:13:46 AM   eval_loss = 0.5384474920504021
03/28 12:13:46 AM   global_step = 1599
03/28 12:13:46 AM   loss = 0.27021937930988055
03/28 12:13:46 AM   mcc = 0.3382393061253004
03/28 12:13:46 AM   rep_loss = 0.0